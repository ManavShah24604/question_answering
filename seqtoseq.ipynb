{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qyIMiUvsHqTa",
        "outputId": "9bf85763-d512-43c7-ce37-ee9b9d4d7733"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: datasets in /home/manav/.local/lib/python3.8/site-packages (2.18.0)\n",
            "Requirement already satisfied: transformers[sentencepiece] in /home/manav/.local/lib/python3.8/site-packages (4.35.2)\n",
            "Requirement already satisfied: fsspec[http]<=2024.2.0,>=2023.1.0 in /home/manav/.local/lib/python3.8/site-packages (from datasets) (2023.10.0)\n",
            "Requirement already satisfied: aiohttp in /home/manav/.local/lib/python3.8/site-packages (from datasets) (3.8.4)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /home/manav/.local/lib/python3.8/site-packages (from datasets) (4.64.1)\n",
            "Requirement already satisfied: multiprocess in /home/manav/.local/lib/python3.8/site-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: xxhash in /home/manav/.local/lib/python3.8/site-packages (from datasets) (3.4.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.19.4 in /home/manav/.local/lib/python3.8/site-packages (from datasets) (0.19.4)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /home/manav/.local/lib/python3.8/site-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: filelock in /home/manav/.local/lib/python3.8/site-packages (from datasets) (3.9.0)\n",
            "Requirement already satisfied: pyarrow-hotfix in /home/manav/.local/lib/python3.8/site-packages (from datasets) (0.6)\n",
            "Requirement already satisfied: numpy>=1.17 in /home/manav/.local/lib/python3.8/site-packages (from datasets) (1.23.4)\n",
            "Requirement already satisfied: requests>=2.19.0 in /home/manav/.local/lib/python3.8/site-packages (from datasets) (2.26.0)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /home/manav/.local/lib/python3.8/site-packages (from datasets) (12.0.0)\n",
            "Requirement already satisfied: pandas in /home/manav/.local/lib/python3.8/site-packages (from datasets) (1.5.3)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/lib/python3/dist-packages (from datasets) (5.3.1)\n",
            "Requirement already satisfied: packaging in /home/manav/.local/lib/python3.8/site-packages (from datasets) (23.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /home/manav/.local/lib/python3.8/site-packages (from transformers[sentencepiece]) (0.4.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /home/manav/.local/lib/python3.8/site-packages (from transformers[sentencepiece]) (0.15.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /home/manav/.local/lib/python3.8/site-packages (from transformers[sentencepiece]) (2023.10.3)\n",
            "Requirement already satisfied: protobuf; extra == \"sentencepiece\" in /home/manav/.local/lib/python3.8/site-packages (from transformers[sentencepiece]) (4.23.4)\n",
            "Requirement already satisfied: sentencepiece!=0.1.92,>=0.1.91; extra == \"sentencepiece\" in /home/manav/.local/lib/python3.8/site-packages (from transformers[sentencepiece]) (0.2.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /home/manav/.local/lib/python3.8/site-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /home/manav/.local/lib/python3.8/site-packages (from aiohttp->datasets) (1.3.3)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /home/manav/.local/lib/python3.8/site-packages (from aiohttp->datasets) (4.0.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /home/manav/.local/lib/python3.8/site-packages (from aiohttp->datasets) (22.2.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /home/manav/.local/lib/python3.8/site-packages (from aiohttp->datasets) (1.8.2)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /home/manav/.local/lib/python3.8/site-packages (from aiohttp->datasets) (6.0.4)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /home/manav/.local/lib/python3.8/site-packages (from aiohttp->datasets) (2.0.12)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/manav/.local/lib/python3.8/site-packages (from huggingface-hub>=0.19.4->datasets) (4.9.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/manav/.local/lib/python3.8/site-packages (from requests>=2.19.0->datasets) (1.26.14)\n",
            "Requirement already satisfied: idna<4,>=2.5; python_version >= \"3\" in /home/manav/.local/lib/python3.8/site-packages (from requests>=2.19.0->datasets) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /home/manav/.local/lib/python3.8/site-packages (from requests>=2.19.0->datasets) (2022.12.7)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /home/manav/.local/lib/python3.8/site-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /home/manav/.local/lib/python3.8/site-packages (from pandas->datasets) (2022.7.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.14.0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/manav/.local/lib/python3.8/site-packages/requests/__init__.py:102: RequestsDependencyWarning: urllib3 (1.26.14) or chardet (5.1.0)/charset_normalizer (2.0.12) doesn't match a supported version!\n",
            "  warnings.warn(\"urllib3 ({}) or chardet ({})/charset_normalizer ({}) doesn't match a supported \"\n",
            "/home/manav/.local/lib/python3.8/site-packages/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
            "  _torch_pytree._register_pytree_node(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['id', 'title', 'context', 'question', 'answers'],\n",
            "        num_rows: 87599\n",
            "    })\n",
            "    validation: Dataset({\n",
            "        features: ['id', 'title', 'context', 'question', 'answers'],\n",
            "        num_rows: 10570\n",
            "    })\n",
            "})\n"
          ]
        }
      ],
      "source": [
        "!pip install datasets transformers[sentencepiece]\n",
        "from datasets import load_dataset\n",
        "from transformers import BertTokenizer\n",
        "\n",
        "# Load the dataset\n",
        "dataset = load_dataset('squad')\n",
        "print(dataset)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "9CMy4SyWbSU5"
      },
      "outputs": [],
      "source": [
        "import torchtext.vocab as vocab\n",
        "\n",
        "embedding_dim = 200\n",
        "glove = vocab.GloVe(name='6B', dim=embedding_dim)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4VFJx2Y_rEBQ",
        "outputId": "bb2c4ee7-fd7a-4b66-91c9-2c4dc0da1ef5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "653 40\n"
          ]
        }
      ],
      "source": [
        "max_len_context = 0\n",
        "max_len_que = 0\n",
        "\n",
        "for some in dataset['train']:\n",
        "  max_len_context = max(max_len_context,(len(some['context'].split())))\n",
        "  max_len_que = max(max_len_que,(len(some['question'].split())))\n",
        "\n",
        "  # if(some['answers']['text']=='' or some['answers']['text']==None or len(some['answers']['text'])==0):\n",
        "  #   print(some['answers'], \" here \")\n",
        "print(max_len_context, max_len_que)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fyS7KnyLbPd1"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "3cLNuJcq1eta"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "subset_indices = np.random.permutation(len(dataset['train']))\n",
        "\n",
        "# Apply the selection\n",
        "dataset[\"train\"] = dataset['train'].select(subset_indices)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 611,
          "referenced_widgets": [
            "f1f8eebe4a2f49d5ab836a9483b87d35",
            "6d25d66f87ac4777a384847f8192fd7d",
            "d0b986912f5d4311b27febff756dc84d",
            "fc081644980e47f19a5a89ccc9487a21",
            "d056cf3774264d85ab2646aea196f1db",
            "f08a5120603741fba45928b84c300c55",
            "220aa364605b49968cfca3d129fb3167",
            "d67a401bb38f409c85d072233232aabf",
            "ba620aea7e064569a4c31941e0355304",
            "2a3a05ccc4234db69ad4b6c907feebd4",
            "aa5613cc8b724c4880e9a6883da1d07c"
          ]
        },
        "id": "VHaerGDDYYOa",
        "outputId": "9fc881ab-3a26-4294-e732-31981dd24feb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['id', 'title', 'context', 'question', 'answers'],\n",
            "        num_rows: 500\n",
            "    })\n",
            "    validation: Dataset({\n",
            "        features: ['id', 'title', 'context', 'question', 'answers'],\n",
            "        num_rows: 10570\n",
            "    })\n",
            "})\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f27ed2ee90304d898478c3281ead7c43",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/500 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['id', 'title', 'context', 'question', 'answers', 'input_ids', 'token_type_ids', 'attention_mask', 'start_positions', 'end_positions'],\n",
            "        num_rows: 500\n",
            "    })\n",
            "    validation: Dataset({\n",
            "        features: ['id', 'title', 'context', 'question', 'answers', 'input_ids', 'token_type_ids', 'attention_mask', 'start_positions', 'end_positions'],\n",
            "        num_rows: 10570\n",
            "    })\n",
            "})\n",
            "[{'text': ['Piedigrotta'], 'answer_start': [127]}, {'text': ['after prior art has been made public'], 'answer_start': [163]}, {'text': ['public money'], 'answer_start': [832]}, {'text': ['wire protocol'], 'answer_start': [178]}, {'text': ['Fort Rosecrans'], 'answer_start': [208]}, {'text': ['559,700'], 'answer_start': [224]}, {'text': ['This was because the sanitation sector was generally receiving less attention from other donors and from governments'], 'answer_start': [592]}, {'text': ['the musical crossover phenomenon'], 'answer_start': [179]}, {'text': ['letters'], 'answer_start': [616]}, {'text': ['Dunkirk'], 'answer_start': [200]}, {'text': ['national mourning'], 'answer_start': [49]}, {'text': ['Indonesia'], 'answer_start': [0]}, {'text': ['US$200 per unit'], 'answer_start': [409]}, {'text': ['the Indian Rebellion of 1857'], 'answer_start': [6]}, {'text': ['July 29, 1958'], 'answer_start': [652]}, {'text': ['Justin Berkmann'], 'answer_start': [266]}, {'text': ['constitutionally authorized appropriation of oil revenues'], 'answer_start': [31]}, {'text': ['24 °C (75 °F)'], 'answer_start': [159]}, {'text': ['Since the presidency of François Mitterrand (1981-1995'], 'answer_start': [494]}, {'text': [\"San Francisco's\"], 'answer_start': [820]}, {'text': ['France'], 'answer_start': [73]}, {'text': ['English'], 'answer_start': [77]}, {'text': ['small genomes'], 'answer_start': [152]}, {'text': ['their own subculture'], 'answer_start': [36]}, {'text': ['the 16 German states'], 'answer_start': [547]}, {'text': ['present tense'], 'answer_start': [56]}, {'text': ['genetic variants'], 'answer_start': [101]}, {'text': ['to either provide irrigation or prevent floods.'], 'answer_start': [471]}, {'text': ['roughly 28–37%'], 'answer_start': [256]}, {'text': ['British Columbia'], 'answer_start': [187]}, {'text': ['Texas'], 'answer_start': [384]}, {'text': ['Louis XVI style'], 'answer_start': [211]}, {'text': ['Alfred M. Mayer'], 'answer_start': [164]}, {'text': ['fractional freezing'], 'answer_start': [369]}, {'text': ['Saussure'], 'answer_start': [827]}, {'text': ['Madonna'], 'answer_start': [22]}, {'text': ['Soviet Union'], 'answer_start': [286]}, {'text': ['the Bosniaks'], 'answer_start': [373]}, {'text': ['My tragedy'], 'answer_start': [713]}, {'text': ['Constantinople'], 'answer_start': [409]}, {'text': ['1348'], 'answer_start': [580]}, {'text': ['Edward Heath'], 'answer_start': [280]}, {'text': ['1,000 kilograms (2,200 pounds) each'], 'answer_start': [267]}, {'text': ['7–1'], 'answer_start': [268]}, {'text': ['Plato'], 'answer_start': [543]}, {'text': ['40,000'], 'answer_start': [553]}, {'text': ['the Chief of the Defence Staff'], 'answer_start': [193]}, {'text': ['3G/4G mobile internet'], 'answer_start': [236]}, {'text': ['CRISPR system provides bacteria with acquired immunity'], 'answer_start': [776]}, {'text': ['West Germanic'], 'answer_start': [17]}, {'text': ['the change in its status and the arrival of the Portuguese royal family'], 'answer_start': [15]}, {'text': ['Oxford and Cambridge'], 'answer_start': [795]}, {'text': ['end'], 'answer_start': [506]}, {'text': ['written report'], 'answer_start': [172]}, {'text': ['individual'], 'answer_start': [175]}, {'text': ['1816'], 'answer_start': [465]}, {'text': ['Gondwana'], 'answer_start': [466]}, {'text': ['their official duties'], 'answer_start': [203]}, {'text': ['11,330'], 'answer_start': [157]}, {'text': ['rotor circuit'], 'answer_start': [559]}, {'text': ['no'], 'answer_start': [572]}, {'text': ['two'], 'answer_start': [149]}, {'text': ['strict class hierarchy'], 'answer_start': [107]}, {'text': ['Lagoon Islands'], 'answer_start': [167]}, {'text': ['Liszt and Hiller'], 'answer_start': [707]}, {'text': ['Alemannic Swiss'], 'answer_start': [109]}, {'text': ['October 1938'], 'answer_start': [471]}, {'text': ['The Wall Street Journal'], 'answer_start': [222]}, {'text': ['Software fault injection'], 'answer_start': [281]}, {'text': ['Ukrainian'], 'answer_start': [1094]}, {'text': ['Jefferson, Madison and Gallatin rivers'], 'answer_start': [80]}, {'text': ['one tornado per hour'], 'answer_start': [850]}, {'text': ['1974'], 'answer_start': [457]}, {'text': ['As a child'], 'answer_start': [0]}, {'text': ['Rex Hospital.'], 'answer_start': [598]}, {'text': ['2.6 miles'], 'answer_start': [1322]}, {'text': [\"one's total identity\"], 'answer_start': [178]}, {'text': ['a background of the principles of immunology'], 'answer_start': [483]}, {'text': ['Talmudic'], 'answer_start': [212]}, {'text': ['uniforms.'], 'answer_start': [914]}, {'text': ['the advent of firearms, new fighting tactics and the need for additional protection'], 'answer_start': [66]}, {'text': ['El Mundo'], 'answer_start': [29]}, {'text': ['when city centres were devastated through the loss of administrative offices, utilities and transport.'], 'answer_start': [385]}, {'text': ['a broadband connection'], 'answer_start': [394]}, {'text': ['an athletic form of entertainment based on a portrayal of a combat sport'], 'answer_start': [83]}, {'text': ['100'], 'answer_start': [341]}, {'text': ['5%'], 'answer_start': [141]}, {'text': ['a wedding dress'], 'answer_start': [167]}, {'text': ['Linux'], 'answer_start': [351]}, {'text': ['Marbury v. Madison'], 'answer_start': [313]}, {'text': ['1933'], 'answer_start': [252]}, {'text': ['Paleo-Balkan peoples'], 'answer_start': [315]}, {'text': ['Brasília, Brazil'], 'answer_start': [59]}, {'text': ['90 per cent'], 'answer_start': [204]}, {'text': ['7'], 'answer_start': [584]}, {'text': ['The east end is polygonal'], 'answer_start': [604]}, {'text': ['Ukraine'], 'answer_start': [121]}, {'text': ['different varieties'], 'answer_start': [267]}, {'text': [\"Universal's German subsidiary\"], 'answer_start': [110]}, {'text': ['fit within the size restrictions or support a compliant extension cable that does'], 'answer_start': [555]}, {'text': ['an Italian refugee from Britain called Orsini'], 'answer_start': [20]}, {'text': ['Proteus'], 'answer_start': [105]}, {'text': ['Huerta'], 'answer_start': [96]}, {'text': ['International Commission on Illumination'], 'answer_start': [4]}, {'text': ['Countrywide Financial'], 'answer_start': [208]}, {'text': ['Libya was occupied by British and French forces'], 'answer_start': [414]}, {'text': ['using a single-lens microscope of his own design'], 'answer_start': [88]}, {'text': ['southern India'], 'answer_start': [211]}, {'text': ['Punjabis'], 'answer_start': [119]}, {'text': [\"Disney's Hollywood Records\"], 'answer_start': [678]}, {'text': ['Most standard meters accurately measure in both directions'], 'answer_start': [747]}, {'text': ['2004 through 2009'], 'answer_start': [38]}, {'text': ['Darlette Johnson'], 'answer_start': [165]}, {'text': ['Buck Privates'], 'answer_start': [471]}, {'text': ['12 January 1949'], 'answer_start': [357]}, {'text': ['Justinian I'], 'answer_start': [253]}, {'text': ['Eclipse'], 'answer_start': [387]}, {'text': ['The nation has no official language'], 'answer_start': [35]}, {'text': ['Murano'], 'answer_start': [169]}, {'text': ['Abdelbaset al-Megrahi'], 'answer_start': [504]}, {'text': ['decay'], 'answer_start': [238]}, {'text': ['one God in three persons'], 'answer_start': [338]}, {'text': ['Driehaus Architecture Prize'], 'answer_start': [494]}, {'text': ['gamut area index'], 'answer_start': [178]}, {'text': ['at the predicted position of the target at the time the projectile reaches it'], 'answer_start': [343]}, {'text': ['1.1 million'], 'answer_start': [153]}, {'text': ['Marvin Braude'], 'answer_start': [130]}, {'text': ['pigs'], 'answer_start': [561]}, {'text': ['play specific content from the disc'], 'answer_start': [202]}, {'text': ['emotion'], 'answer_start': [227]}, {'text': ['Feria hair color advertisements'], 'answer_start': [386]}, {'text': ['Sudan'], 'answer_start': [290]}, {'text': ['Central Asia'], 'answer_start': [102]}, {'text': ['Fujiwara'], 'answer_start': [535]}, {'text': ['phonological and morphological peculiarities of Greek; this has led some linguists to propose a hypothetical closer relationship between Greek and Armenian'], 'answer_start': [363]}, {'text': ['the Huns'], 'answer_start': [426]}, {'text': ['Parque Batlle'], 'answer_start': [0]}, {'text': ['mass media'], 'answer_start': [147]}, {'text': ['Jasmine Bligh'], 'answer_start': [49]}, {'text': ['i rossoneri'], 'answer_start': [235]}, {'text': ['Richard Stallman'], 'answer_start': [33]}, {'text': ['Russian Revolution'], 'answer_start': [238]}, {'text': ['ESPN took over the package Setanta'], 'answer_start': [188]}, {'text': ['an altar'], 'answer_start': [438]}, {'text': ['the esteem and prestige of the senators'], 'answer_start': [45]}, {'text': ['eleven'], 'answer_start': [1865]}, {'text': ['psychologists'], 'answer_start': [1018]}, {'text': ['Heat'], 'answer_start': [247]}, {'text': ['Venetian'], 'answer_start': [87]}, {'text': ['awaiting the building of a new stadium in Escondido'], 'answer_start': [242]}, {'text': ['Queen Victoria and Prince Albert.'], 'answer_start': [185]}, {'text': ['driven by an expectation that coal would soon become scarce'], 'answer_start': [236]}, {'text': ['HVDC Cross Sound Cable'], 'answer_start': [57]}, {'text': ['Soviet Union'], 'answer_start': [580]}, {'text': ['Dennis Hastert'], 'answer_start': [415]}, {'text': ['January 17, 1961'], 'answer_start': [3]}, {'text': ['Zen'], 'answer_start': [0]}, {'text': [\"Bermuda's cultural connections with the West Indies\"], 'answer_start': [526]}, {'text': ['exile'], 'answer_start': [982]}, {'text': ['1675'], 'answer_start': [362]}, {'text': ['Real Madrid'], 'answer_start': [369]}, {'text': ['The Austrians had ultimately made little progress in the campaign in Saxony despite Hochkirch and had failed to achieve a decisive breakthrough'], 'answer_start': [240]}, {'text': ['the previous play'], 'answer_start': [114]}, {'text': ['bitumen'], 'answer_start': [8]}, {'text': ['electrical engineer'], 'answer_start': [208]}, {'text': ['only one'], 'answer_start': [429]}, {'text': ['1254'], 'answer_start': [223]}, {'text': ['San Francisco'], 'answer_start': [76]}, {'text': ['\"May Gray\"'], 'answer_start': [486]}, {'text': ['JellyBean Benetiz'], 'answer_start': [903]}, {'text': ['two'], 'answer_start': [179]}, {'text': [\"During the early 1900s, black people made up nearly half of the state's population\"], 'answer_start': [195]}, {'text': ['for ease of identification'], 'answer_start': [109]}, {'text': ['the Housing Grants, Construction and Regeneration Act'], 'answer_start': [1068]}, {'text': ['New Zealand'], 'answer_start': [468]}, {'text': ['international bond rating agencies'], 'answer_start': [133]}, {'text': ['catenary voltage'], 'answer_start': [496]}, {'text': ['2010'], 'answer_start': [283]}, {'text': ['Shun'], 'answer_start': [385]}, {'text': ['Real Madrid'], 'answer_start': [508]}, {'text': ['1965'], 'answer_start': [45]}, {'text': ['up to 9 meters'], 'answer_start': [122]}, {'text': ['fine-grained polycrystalline form'], 'answer_start': [838]}, {'text': ['Latin and Cyrillic'], 'answer_start': [631]}, {'text': ['Libyan Arab Republic'], 'answer_start': [84]}, {'text': ['Randy Jackson'], 'answer_start': [91]}, {'text': ['eastern Ukraine'], 'answer_start': [488]}, {'text': ['an eager embrace of its ideals would corrupt undergraduate education'], 'answer_start': [248]}, {'text': ['strongly opposed to any further alliance of German states'], 'answer_start': [820]}, {'text': ['US'], 'answer_start': [7]}, {'text': ['tourists'], 'answer_start': [596]}, {'text': ['Letter case'], 'answer_start': [0]}, {'text': ['2006'], 'answer_start': [742]}, {'text': ['Andorra'], 'answer_start': [3]}, {'text': ['stridulate'], 'answer_start': [983]}, {'text': ['300 million'], 'answer_start': [447]}, {'text': ['Bantu names'], 'answer_start': [257]}, {'text': ['United Arab Republic'], 'answer_start': [756]}, {'text': ['provided an important outlet for Greek culture, via the creation of colonies and trade routes along the way'], 'answer_start': [195]}, {'text': ['scholasticism'], 'answer_start': [730]}, {'text': ['The Roman Missal'], 'answer_start': [0]}, {'text': ['repudiated it entirely'], 'answer_start': [593]}, {'text': ['1859 to 1873'], 'answer_start': [53]}, {'text': ['Brazil'], 'answer_start': [259]}, {'text': ['Michael Greenberger'], 'answer_start': [187]}, {'text': ['Club Row'], 'answer_start': [218]}, {'text': ['I Am Because We Are'], 'answer_start': [349]}, {'text': ['Chicago'], 'answer_start': [67]}, {'text': ['nomadic or semi-nomadic'], 'answer_start': [26]}, {'text': ['issued orders allowing Athanasius to return to his episcopal see'], 'answer_start': [746]}, {'text': ['the Dalai Lama'], 'answer_start': [181]}, {'text': ['fragile'], 'answer_start': [355]}, {'text': ['Anthony Allen'], 'answer_start': [240]}, {'text': ['90 m (300 ft) per day'], 'answer_start': [518]}, {'text': ['Neville Chamberlain'], 'answer_start': [314]}, {'text': ['Portuguese-based legal system'], 'answer_start': [468]}, {'text': ['Norfolk Island National Park'], 'answer_start': [266]}, {'text': ['high treason'], 'answer_start': [340]}, {'text': ['London'], 'answer_start': [668]}, {'text': ['commutator'], 'answer_start': [304]}, {'text': ['non-ballistic factors'], 'answer_start': [482]}, {'text': ['nutritional information'], 'answer_start': [302]}, {'text': ['conservatism'], 'answer_start': [654]}, {'text': ['1,021'], 'answer_start': [77]}, {'text': ['US president Barack Obama'], 'answer_start': [256]}, {'text': ['immigrants'], 'answer_start': [795]}, {'text': ['Brooklyn'], 'answer_start': [401]}, {'text': ['1999'], 'answer_start': [289]}, {'text': ['Church Building Act of 1818'], 'answer_start': [10]}, {'text': ['A$3.50 per m3'], 'answer_start': [428]}, {'text': ['BitLocker, Hyper-V, the ability to join a domain, and the ability to install Windows Media Center as a paid add-on'], 'answer_start': [401]}, {'text': ['more than 20'], 'answer_start': [261]}, {'text': ['1886'], 'answer_start': [119]}, {'text': ['high cultural references of 1960s rock artists'], 'answer_start': [883]}, {'text': ['in nerves'], 'answer_start': [496]}, {'text': ['782 BC'], 'answer_start': [594]}, {'text': ['1955'], 'answer_start': [4]}, {'text': ['August'], 'answer_start': [497]}, {'text': ['1671'], 'answer_start': [3]}, {'text': ['small sekreton'], 'answer_start': [396]}, {'text': ['television set or a computer monitor'], 'answer_start': [300]}, {'text': ['1959'], 'answer_start': [3]}, {'text': ['Ground Control'], 'answer_start': [281]}, {'text': ['40,000'], 'answer_start': [67]}, {'text': ['Polycom'], 'answer_start': [252]}, {'text': ['John Schael'], 'answer_start': [558]}, {'text': ['faster tempos'], 'answer_start': [660]}, {'text': ['Tuesday'], 'answer_start': [378]}, {'text': ['The Economist'], 'answer_start': [77]}, {'text': ['motorway'], 'answer_start': [848]}, {'text': ['March 1949'], 'answer_start': [3]}, {'text': ['humans'], 'answer_start': [438]}, {'text': ['85%'], 'answer_start': [114]}, {'text': ['twice as large'], 'answer_start': [142]}, {'text': ['41 and 68'], 'answer_start': [9]}, {'text': ['64.5 million'], 'answer_start': [350]}, {'text': ['hilly and sometimes forested'], 'answer_start': [245]}, {'text': ['sent into exile'], 'answer_start': [1261]}, {'text': ['17th century'], 'answer_start': [92]}, {'text': ['the early modern period'], 'answer_start': [154]}, {'text': ['the Students Publishing Company'], 'answer_start': [321]}, {'text': ['83%'], 'answer_start': [0]}, {'text': ['Julie Bishop'], 'answer_start': [64]}, {'text': ['Governor-General'], 'answer_start': [175]}, {'text': ['British Prime Minister David Cameron'], 'answer_start': [313]}, {'text': ['coconut palms'], 'answer_start': [280]}, {'text': ['French'], 'answer_start': [280]}, {'text': ['the Parliament'], 'answer_start': [476]}, {'text': ['Malaysia'], 'answer_start': [441]}, {'text': ['April to October'], 'answer_start': [240]}, {'text': ['passage migrants'], 'answer_start': [251]}, {'text': ['state, local, and international agencies'], 'answer_start': [901]}, {'text': ['Christian'], 'answer_start': [131]}, {'text': ['West 10th Street'], 'answer_start': [866]}, {'text': ['Vladimir Lenin'], 'answer_start': [24]}, {'text': ['electronic'], 'answer_start': [438]}, {'text': ['ideological gap'], 'answer_start': [547]}, {'text': ['understanding the genetics'], 'answer_start': [629]}, {'text': ['2006 at Sundernagar'], 'answer_start': [1132]}, {'text': ['Brazil'], 'answer_start': [425]}, {'text': ['Appleton & Jones'], 'answer_start': [288]}, {'text': ['a form of comic opera'], 'answer_start': [578]}, {'text': ['move weak assets off their balance sheets'], 'answer_start': [457]}, {'text': ['1778–83'], 'answer_start': [612]}, {'text': ['nontheistic'], 'answer_start': [25]}, {'text': ['to diversify away from gaming'], 'answer_start': [245]}, {'text': ['5 February 1987'], 'answer_start': [268]}, {'text': ['Oklahoma Gazette'], 'answer_start': [150]}, {'text': ['protagonist'], 'answer_start': [40]}, {'text': ['securities'], 'answer_start': [751]}, {'text': [\"the Peasants' Revolt\"], 'answer_start': [769]}, {'text': ['song'], 'answer_start': [768]}, {'text': ['Houston'], 'answer_start': [0]}, {'text': ['the suburbs'], 'answer_start': [113]}, {'text': ['rich environments'], 'answer_start': [116]}, {'text': ['Artemis'], 'answer_start': [616]}, {'text': ['24 September 1973'], 'answer_start': [42]}, {'text': ['SQL'], 'answer_start': [304]}, {'text': ['nobility'], 'answer_start': [69]}, {'text': ['infectious disease'], 'answer_start': [204]}, {'text': ['southern Italian'], 'answer_start': [601]}, {'text': ['due to potential ambiguity with pri'], 'answer_start': [348]}, {'text': ['8.1 on the Richter scale'], 'answer_start': [109]}, {'text': ['1500'], 'answer_start': [259]}, {'text': ['James Cameron'], 'answer_start': [446]}, {'text': [\"The Queen's Diamond Jubilee Galleries\"], 'answer_start': [48]}, {'text': ['the Virgin Mary'], 'answer_start': [212]}, {'text': ['Rolling Stone'], 'answer_start': [1593]}, {'text': ['Spanish'], 'answer_start': [0]}, {'text': ['more than $70 million'], 'answer_start': [576]}, {'text': ['1180'], 'answer_start': [44]}, {'text': ['multi-color white LEDs'], 'answer_start': [152]}, {'text': ['defence equipment and technology.'], 'answer_start': [37]}, {'text': ['Malayo-Polynesian'], 'answer_start': [265]}, {'text': ['insects themselves'], 'answer_start': [407]}, {'text': ['zahir'], 'answer_start': [30]}, {'text': ['Coleman A. Young Municipal Center'], 'answer_start': [124]}, {'text': ['National Government'], 'answer_start': [712]}, {'text': ['16th'], 'answer_start': [168]}, {'text': ['Eusébio'], 'answer_start': [164]}, {'text': ['the lack of instructions provided by the operating system on the functions accessed through the user interface'], 'answer_start': [157]}, {'text': ['beats'], 'answer_start': [521]}, {'text': ['ring-porous'], 'answer_start': [3]}, {'text': ['Mughal Emperor Aurangzeb'], 'answer_start': [346]}, {'text': ['FIFA'], 'answer_start': [143]}, {'text': ['Washington Heights'], 'answer_start': [57]}, {'text': ['1520s'], 'answer_start': [233]}, {'text': ['Kroemer Braunstein'], 'answer_start': [149]}, {'text': ['Lagrangian'], 'answer_start': [321]}, {'text': ['1996'], 'answer_start': [349]}, {'text': ['trees and fresh water.'], 'answer_start': [66]}, {'text': ['atheist / non-theistic'], 'answer_start': [772]}, {'text': ['architectural character'], 'answer_start': [402]}, {'text': ['12,000'], 'answer_start': [103]}, {'text': ['poor farmers who needed cheap labour'], 'answer_start': [591]}, {'text': ['organized religion'], 'answer_start': [64]}, {'text': ['The Saale in the west and the Weiße Elster in the east'], 'answer_start': [1390]}, {'text': ['Romanesque'], 'answer_start': [117]}, {'text': ['Anne of Bohemia'], 'answer_start': [41]}, {'text': [\"Commissioner's Plan of 1811\"], 'answer_start': [182]}, {'text': ['analyzing speech patterns'], 'answer_start': [1214]}, {'text': ['loss of self-control and violent emotional outbursts'], 'answer_start': [528]}, {'text': ['Color'], 'answer_start': [0]}, {'text': ['19th'], 'answer_start': [43]}, {'text': ['Hydrochloric'], 'answer_start': [161]}, {'text': ['rivercane, cedar, and other woods'], 'answer_start': [265]}, {'text': ['slow the absorption of sugar'], 'answer_start': [1292]}, {'text': ['2009'], 'answer_start': [11]}, {'text': ['1881'], 'answer_start': [847]}, {'text': ['Blades'], 'answer_start': [116]}, {'text': ['the Vedas'], 'answer_start': [439]}, {'text': ['Schuylkill Expressway'], 'answer_start': [155]}, {'text': ['17th'], 'answer_start': [15]}, {'text': ['intrastate federalism'], 'answer_start': [131]}, {'text': ['Hurricane Katrina'], 'answer_start': [265]}, {'text': ['Infrared astronomy'], 'answer_start': [217]}, {'text': ['judiciary'], 'answer_start': [557]}, {'text': ['Nearly 8 million'], 'answer_start': [457]}, {'text': ['season eight'], 'answer_start': [468]}, {'text': ['talking monetary policy with the market'], 'answer_start': [736]}, {'text': ['a segment on 60 Minutes'], 'answer_start': [292]}, {'text': ['hydrogen'], 'answer_start': [113]}, {'text': ['incessant cavalry charges'], 'answer_start': [404]}, {'text': ['English and Scotch-Irish'], 'answer_start': [240]}, {'text': ['German numerical superiority'], 'answer_start': [27]}, {'text': ['1842'], 'answer_start': [197]}, {'text': ['plastic Olympic flames'], 'answer_start': [215]}, {'text': ['Leo Tolstoy'], 'answer_start': [397]}, {'text': ['28 April 1738'], 'answer_start': [404]}, {'text': ['some of the most prominent'], 'answer_start': [333]}, {'text': ['Chen Yuanguang'], 'answer_start': [85]}, {'text': ['the tide'], 'answer_start': [276]}, {'text': ['early model F-16 aircraft converted to QF-16 configuration'], 'answer_start': [799]}, {'text': ['21 May 1502'], 'answer_start': [65]}, {'text': ['Sony Music Entertainment'], 'answer_start': [596]}, {'text': ['Madonna'], 'answer_start': [28]}, {'text': ['Emperor Napoleon III of France'], 'answer_start': [490]}, {'text': ['TU'], 'answer_start': [38]}, {'text': ['22'], 'answer_start': [211]}, {'text': ['\"Refresh\" and \"Reset\" functions, including system recovery from USB drive'], 'answer_start': [533]}, {'text': ['acoustic'], 'answer_start': [266]}, {'text': ['559.8 EJ'], 'answer_start': [335]}, {'text': ['she dedicated the next two decades to the consolidation of her administration.'], 'answer_start': [924]}, {'text': ['a trademark'], 'answer_start': [533]}, {'text': ['wife of Toyotomi Hideyoshi'], 'answer_start': [284]}, {'text': ['southern Sichuan'], 'answer_start': [45]}, {'text': ['the Austrians went almost bankrupt at the end of war.'], 'answer_start': [863]}, {'text': ['tourism and services, but also has commerce, shipbuilding and agriculture'], 'answer_start': [288]}, {'text': ['20 October 1944'], 'answer_start': [3]}, {'text': ['Court of Cassation'], 'answer_start': [50]}, {'text': ['the Entente'], 'answer_start': [143]}, {'text': [\"Albert's\"], 'answer_start': [504]}, {'text': ['Austrian forces'], 'answer_start': [85]}, {'text': ['sets of constellations'], 'answer_start': [591]}, {'text': ['the Estonian SSR'], 'answer_start': [272]}, {'text': ['129,779'], 'answer_start': [52]}, {'text': ['wage and benefits package'], 'answer_start': [674]}, {'text': ['donkeys'], 'answer_start': [517]}, {'text': ['Golden Age'], 'answer_start': [462]}, {'text': ['the bronchi and bronchioles'], 'answer_start': [100]}, {'text': ['those who spray paint, bakers and those who process food, nurses, chemical workers, those who work with animals, welders, hairdressers and timber workers'], 'answer_start': [476]}, {'text': ['Causing a Commotion'], 'answer_start': [1064]}, {'text': ['180'], 'answer_start': [343]}, {'text': ['1967'], 'answer_start': [29]}, {'text': ['the British monarchy'], 'answer_start': [48]}, {'text': ['West Africa'], 'answer_start': [346]}, {'text': ['1992'], 'answer_start': [580]}, {'text': ['Oscar Niemeyer'], 'answer_start': [113]}, {'text': ['the Bay of Fundy'], 'answer_start': [281]}, {'text': ['2,300'], 'answer_start': [39]}, {'text': ['among the top twenty'], 'answer_start': [140]}, {'text': ['Melbourne'], 'answer_start': [245]}, {'text': ['I Believe'], 'answer_start': [346]}, {'text': ['of the sick man of Europe'], 'answer_start': [451]}, {'text': ['policy makers'], 'answer_start': [254]}, {'text': ['108,000'], 'answer_start': [194]}, {'text': ['Philadelphia International Airport (PHL)'], 'answer_start': [37]}, {'text': ['public haruspices'], 'answer_start': [805]}, {'text': ['weaker'], 'answer_start': [455]}, {'text': [\"Pat O'Brien\"], 'answer_start': [457]}, {'text': ['mycolic acid capsule'], 'answer_start': [590]}, {'text': ['single hole (temporal fenestra) low on each side of the skull'], 'answer_start': [545]}, {'text': ['candombe'], 'answer_start': [466]}, {'text': ['3.5 million'], 'answer_start': [350]}, {'text': ['hydrogen production from protons'], 'answer_start': [547]}, {'text': ['Dean of Arts and Letters'], 'answer_start': [625]}, {'text': ['2002'], 'answer_start': [3]}, {'text': ['Juan Rodriguez Way'], 'answer_start': [425]}, {'text': ['Organisation for African Unity'], 'answer_start': [416]}, {'text': ['high culture'], 'answer_start': [108]}, {'text': ['Sir Charles Allom'], 'answer_start': [180]}, {'text': ['Anglo-Egyptian Treaty'], 'answer_start': [265]}, {'text': ['the Republic of the Congo'], 'answer_start': [263]}, {'text': [\"Yerevan's FC Ararat\"], 'answer_start': [384]}, {'text': ['One or two knots at each end are for keeping hold of the rope while doing the routine.'], 'answer_start': [254]}, {'text': ['YouTube Gaming'], 'answer_start': [282]}, {'text': ['education of girls is less valued'], 'answer_start': [568]}, {'text': ['$500–950'], 'answer_start': [476]}, {'text': ['Martin Heidegger'], 'answer_start': [13]}, {'text': ['José Batlle y Ordóñez'], 'answer_start': [36]}, {'text': ['Maratha military resurgence'], 'answer_start': [526]}, {'text': ['gender'], 'answer_start': [771]}, {'text': ['The City Parliament'], 'answer_start': [0]}, {'text': ['1921'], 'answer_start': [82]}, {'text': ['to treat waste water without chemicals or electricity'], 'answer_start': [55]}, {'text': ['90% to 96%'], 'answer_start': [106]}, {'text': ['medical scrubs'], 'answer_start': [600]}, {'text': ['simple colors'], 'answer_start': [756]}, {'text': [\"his failure to respond directly to The Sun's attacks\"], 'answer_start': [747]}, {'text': ['54 million'], 'answer_start': [187]}, {'text': ['70 staff'], 'answer_start': [168]}, {'text': ['The Iroquois philosophy'], 'answer_start': [318]}, {'text': ['R&B'], 'answer_start': [29]}, {'text': ['May 20, 1926'], 'answer_start': [24]}, {'text': ['Highway Hi-Fi 16 2⁄3 rpm record'], 'answer_start': [304]}, {'text': ['dam'], 'answer_start': [282]}, {'text': ['Sony'], 'answer_start': [677]}, {'text': ['aéronef'], 'answer_start': [487]}, {'text': ['Prefixes'], 'answer_start': [329]}, {'text': [\"NATO's Allied Command Europe\"], 'answer_start': [97]}, {'text': ['Nikolai Yudenich'], 'answer_start': [67]}, {'text': ['in trans'], 'answer_start': [454]}, {'text': ['late 11th century'], 'answer_start': [430]}, {'text': ['arrive at a description'], 'answer_start': [438]}, {'text': ['captured the French colonies in Senegal in 1758'], 'answer_start': [74]}, {'text': ['Vienna Literary Agreement'], 'answer_start': [56]}, {'text': ['military force'], 'answer_start': [83]}, {'text': ['1990'], 'answer_start': [488]}, {'text': ['five major mass extinctions'], 'answer_start': [27]}, {'text': ['sea level'], 'answer_start': [44]}, {'text': ['September'], 'answer_start': [227]}, {'text': ['tectonic'], 'answer_start': [354]}, {'text': ['federally-governed Generality Lands (Generaliteitslanden)'], 'answer_start': [107]}, {'text': ['Jane Austen'], 'answer_start': [891]}, {'text': ['$1 trillion'], 'answer_start': [98]}, {'text': ['Commissionerate of Health and Family Welfare'], 'answer_start': [4]}, {'text': ['3%'], 'answer_start': [323]}, {'text': ['Glial cells'], 'answer_start': [636]}, {'text': ['300 mL/day'], 'answer_start': [531]}, {'text': ['five'], 'answer_start': [379]}, {'text': ['United Nations Security Council'], 'answer_start': [869]}, {'text': ['US$13.1 billion'], 'answer_start': [168]}, {'text': ['natural selection and selective breeding'], 'answer_start': [45]}, {'text': ['Gordon Foxley'], 'answer_start': [46]}, {'text': ['the Yongle Emperor'], 'answer_start': [349]}, {'text': ['Tollywood'], 'answer_start': [455]}, {'text': ['Emotion regulation'], 'answer_start': [0]}, {'text': ['New York'], 'answer_start': [117]}, {'text': ['Nagasaki'], 'answer_start': [101]}, {'text': ['1295'], 'answer_start': [235]}, {'text': ['the FCC'], 'answer_start': [189]}, {'text': ['10 million'], 'answer_start': [136]}, {'text': ['Models of the human ear-brain'], 'answer_start': [782]}, {'text': ['June 16, 1963'], 'answer_start': [77]}, {'text': ['the Georgian SSR'], 'answer_start': [162]}, {'text': ['coconut'], 'answer_start': [48]}, {'text': ['there was no peace treaty'], 'answer_start': [643]}, {'text': ['near Kenmore Square'], 'answer_start': [133]}, {'text': ['standard German orthography'], 'answer_start': [279]}, {'text': ['42.6%'], 'answer_start': [602]}]\n",
            "['In which district is \"Virgil\\'s tomb\" located?', 'When can patents not be filed in most countries?', 'What are most higher education student costs supported with?', 'What is a way for programmers to use the DBMS?', 'What names was given to coastal artillery batteries erected shortly after 1852?', 'What is the population of Beer Sheva?', 'WHy did the foundation make the switch ', 'What phenomenon sees classical musicians achieving success in popular music?', 'What did Montini take charge of responding to on behalf of Pius XII?', 'Where did Napoleon III meet Victoria and Albert, before accompanying them to Paris?', 'What did the State Council declare a period of?', 'Name the largest country in Southeast Asia.', 'How much did the early LEDs cost?', 'What caused the British East India Company to lose control of India?', 'When did Tucson get the most rain in 24 hours?', 'who was the resident of the Ministry of Sound?', 'What is the Alaska Permanent Fund?', 'In Cyprus, what is the average temperature during the day?', 'When did the French authorities adopted the pro-European Unification position? ', \"What region's post-punk scene incorporated ideas from Theater of Cruelty?\", 'In what country did Baldwin and Forlanini get together?', 'What is the official language of Nigeria?', 'Why is a plant chosen for the study of its cells?', 'What do the fans have?', 'The amended article 23 now defines the participation of the Federal Council and what else?', 'What is used in place of the future tense?', 'What can the clearance of pathogens be influenced by in an individual?', 'The Dujiangyan irrigation system was used for what purpose?', 'What is the number of non-white citizens in the United States?', 'What province became more popular and saw a increase in population after the war?', 'What state notably executes 40% of those given the death penalty?', 'What term is used to express the first wave of neoclassicism in France?', 'Who was the physicist to report that a tone could be rendered inaudible.', 'What is a strong ale called when it is frozen partially, and then the ice is removed again and again?', 'Who was a member of the third ascent of Mont Blanc?', 'Who writes and creates most of her own music?', 'Who supplied assistance to the Chinese military?', 'Other than the Roman Catholics, who else uses Latin?', \"What did Frédéric label the place in which he placed Maria and her mother's letters about the unlikely marriage?\", 'Where did the Roman Empire move to in 330 AD?', 'In what year was the Order of the Garter established?', 'Who did the Sun support in 1974?', 'How much did each satellite for the BeiDou-1 system weigh?', \"What was the final score of England's worst ever defeat?\", 'Who thought the senses were less important, Aristotle or Plato?', 'How many of its numerous named locations are communities?', 'Who is the highest ranking member of the Armed Forces?', 'In recent years, what usage has risen dramatically?', 'How can bacteria resist virus DNA?', 'What language family does Old English belong to?', 'What provoked the modernization and expansion of the Brazilian administrative, civic, economical, military, educational, and scientific apparatus?', 'At which universities were canon law degrees abolished?', 'What happens to infected plant cells?', 'What did researcher Geng Qingguo say was sent to the State Seismological Bureau?', 'Who made the choices of personal religious practices in Rome? ', 'In which year did the period known as the \"Era of Good Feelings\" begin?', 'What continent moved to the southern-most part of the earth in the Cambrian era?', 'It is only considered political corruption if the act directly relates to what?', 'How many Oklahomans speak Vietnamese?', 'Where can variable resistance be created?', 'In heterosexual adolescent couples, is there a significant difference in the rates of male and female aggressors?', 'How many executive orders were issued to help prevent discrimination?', 'What was society based on during the Tukugawa period?', 'How did Byron name the Tuvalu islands?', 'On March 23, 1833, who headlined and performed with Chopin at a concert?', 'What dialect is Bernese German?', 'When did Von Neumann get married for a second time?', 'Along with the New York Times, what national daily newspaper is based in New York?', 'What is one example of failure testing?', \"What was 'Little Russian'?\", 'What rivers form the Missouri River?', 'How fast did the 1912 tornado outbreak make tornadoes?', 'When did Guinea-Bissau become independent?', 'When did Steven Spielberg have trouble dealing with being an Orthodox Jew?', 'What is the name of the hospital in West Raleigh?', 'How wide was the widest tornado ever?', 'What are gender identity, ethnic identity, and occupational identity aspects of?', 'What pre-requisite should enrollees in the advanced immunology course have?', 'what texts were legislated by the Tanarim and Amoraim?', 'Although the militia were mainly made of volunteers what item distinguish them from other militia companies?', 'Why were there armor changes in the 1500s?', 'Which paper published an article that raised questions about the handling of the investigation?', 'What caused the most production disruption?', 'What has the been a massive increase in the number of households with in Greece?', 'What is professional wrestling?', 'An equal-tempered semitone is subdivided into how many cents?', \"What was the Congo's annual increase in gross domestic product in the early '80s?\", 'What was Madonna wearing during the performance of \"Like A Virgin\" at the VMA?', 'DeveloperWorks has content about open industry standard technologies like Java and SOA, what is one other industry standard technology it has resources for?', 'What is the court case that established judicial review?', 'In what year was The Invisible Man made?', 'What peoples where in the Balkans?', 'Where was the 2007/2008 Human Development Report launched?', 'How much of the native population near Massachusetts was killed by smallpox in the epidemic between 1617 and 1619?', 'What is the lowest score on the Democracy Score scale?', 'What shape does the east end of French chapels typically have?', 'What is the posulated homeland region of the Slavs?', 'What is the differenctiation between Catalan and Valencian?', 'Prior to his work in America, where was Joe Pasternak employed?', 'Due to size restrictions compliant devices must what?', 'Who attempted to assassinate Napoleon?', 'What is the second most massive Neptunian moon? ', 'The Plan de Guadalupe refused to recognize who as the president?', 'What does the CIE stand for?', 'What company used a classic bait-and-switch method by advertising low interest rates?', 'What happened to Libya right after World War II?', 'How was he able to see bacteria?', 'In what part of India did the Tamil dynasties rule?', 'What is the largest ethnic group in Pakistan?', 'After leaving Capitol, who did Queen sign with?', 'Why is a second meter usually unnecessary to monitor electricity use?', 'Between what years did worldwide renewable energy capacity grow at rates of 10 to 60 percent annually?', \"Who was the first person to notice Beyonce's singing ability?\", 'What military comedy did Bud Abbott and Lou Costello star in?', 'What date did the Soviet Council of Ministers issue a declaration to remove native Estonians?', 'Under what Emperor did this group sit?', 'IBM created the software framework known as?', 'What is the official language of Eritrea?', 'Where is the Basilica of Santi Maria e Donato located?', 'Along with Lamin Khalifah Fhimah, who was suspected of the attack on Pan Am Flight 103?', 'Along with insect infestation, what process can discolor wood and make it look like heartwood?', 'What is the trinity in Christianity?', 'Which prize does the Architecture School at Notre Dame give out?', 'What does GAI stand for?', 'Projectiles must either be guided to the target or aimed where?', 'How many of the people who live in Houston were foreign born?', 'What is the name of the bike trail that goes through Santa Monica?', 'What animal are European parties responsible for releasing in Bermuda?', 'What did LaserStacks software enable Mac users to do?', 'Because dogs respond to voices the same way humans do, they are able to recognize what in human sounds, making them social?', \"What advertisement was Beyoncé's skin supposedly lightened in?\", 'Where were they?', 'To where were the Karachays exiled?', 'What was the name of the prominent clan during the Heian period?', 'What other things do the two languages seem to have in common ?', 'Who destroyed the Burgundian kingdom in 436?', 'What major public central park is located south of Avenida Italia? ', 'Besides being the official language and language of education, what other group uses Catalan?', 'Who was the first person to speak on BBC when it was turned back on following World War II?', 'What is the nickname given to A.C. Milan?', 'Who founded the Free Software Foundation?', 'Which organization did Michael Rostovtzeff flee from?', 'Who took over the package from Sentana?', 'What religious element could be found in all Roman households?', \"What was the general source of the Roman senate's authority?\", \"How many editions were published of Sarah Trimmer's history textbook for children?\", 'Who migrated to the theory of specificity en mass?', \"Beyonce's first fragrance had what name?\", 'Under whose rule was Carnival established in the 16th century?', 'Why were the Tucson Padres temporarily in Tucson?', 'What two dignitaries where at his first performance in London?', 'Why was solar technology developed in the 1860s?', 'What static inverter plant lies near New Haven? ', 'What nation was considered the leader in the nuclear arms race?', 'Who was speaker of the house When Tom Delay was Majority leader?', 'On what date did Eisenhower deliver his farewell speech?', 'What Buddhist teachings are often full of paradox?', 'What are Dame Lois Browne-Evans and her husband putting an emphasis on?', 'What was teh fate of King Farouk after the coup?', \"When did censuses start being conducted in St. John's?\", 'What team did Barcelona beat in El Clasico in 2010?', 'What was the result of the victory for the Austrians?', 'The outcome of which play determines the placement of the ball when a penalty is declined?', 'What is another term for asphalt?', \"What job did Steven Spielberg's father have?\", 'How many expansion slots did the Macintosh IIsi have?', 'In what year was Plymouth recognized as a town?', \"Where did the torch start it's North American route?\", 'What have locals coined the morning time in May?', 'By what other name is John Benetiz known?', 'In the Bermuda land mass, how many bays are named \"Horseshoe Bay\"?', \"what percentage of florida was black in the early 1900's \", 'Why was the code patterned so that most codes were together?', \"What was the name of the legistlation leading to the change in ARCUK's name?\", 'Norfolk Island fell under whose responsibility during World War II?', 'Who reassured investors by showing the risk of complex financial innovation products was actually less than they proved to be?', 'What specification is similar for both Amtrak and Septa systems?', 'In what year did NBC beat American Idol in the ratings for the first time?', 'What dynasty did Zicheng form?', 'What team beat Barcelona in La Liga in the 2006-07 season?', \"In what year was the Beatles made MBE's?\", 'How large was the displacement?', 'How is copper normally supplied?', 'Serbo-Croatian is the only Slavic language to use what two scripts together?', 'What was the name of the government Gaddafi set up after overthrowing the monarchy?', 'Who was the mentor this season?', 'Where is Surzhyk used?', \"What was Porter's reason for striking down the research university?\", 'As Prussia sought to incorporated several German kingdoms, what stance did France assume?', 'In what country does one kilowatt-hour of electricity causes 1.34 pounds of CO 2 emission?', 'Bostons rich history attracts many what each year?', 'What is often prescribed by the grammar of a language or by conventions of a particular discipline?', 'According to business journalist Kimberly Amadeo, when did the first signs of decline in real estate occur?', 'Where has Catalan always been the only language?', 'What do crickets do in order to attract or repel a mate?', 'Together how records have they sold ?', 'What type of names do \"blacks\" have?', 'What was the Egyptian-Syrian alliance called?', 'How was this achievement of advancing culture undertaken ?', 'What was the name of the school of thought that combined theology and philosophy?', 'The rituals for the correct way to enjoy Mass is listed in what text ?', \"What did Paul Feyerabend ultimate do to Popper's philosophy of science?\", 'What was the time span that von Roon acted as minister?', 'What country had a post-punk scene after a generation of rock?', 'Who was the former director of the CFTC that testified before the Senate Committee on Commerce, Science, and Transportation on June 3, 2008?', 'Which strip is known for its numerous nightclubs and lounges?', 'What was the documentary Madonna produced and wrote about the Malawis?', 'Where was the \"Kanye West Foundation\" founded?', 'What is the lifestyle of hunter-gatherers?', 'How did Valens get him to return?', 'Who used to reside in the Potala Palace?', 'Compared to hickory and ash, what adjective might be used for a maple baseball bat?', 'What famous player from Trojans RFC also played for the Leicester Tigers?', 'At what rate have glaciers travelled during surges?', 'Which notable government official did The Times ally with in the 1930s whom practised German appeasement?', \"Macau's legal system comes from what tradition?\", 'Where can the tallest tree-fern in the world be found?', 'What was Edward Oxford charged with after his assassination attempt?', 'Where was the Foreign Ministers conference held?', 'What component of a universal motor is most likely to fail?', 'What affected the effective ceiling for heavy AA guns?', 'What did the studies show there was a lack of understanding of by the population?', 'In 1918 which way did the French idealogies shift that effected Cubism?', 'How many people died on the General Slocum?', \"What US president was critical of Egypt's repression of Muslim Brotherhood?\", 'Who replaced the wealthy?', 'In what borough is the Ditmas Park neighborhood located?', \"What was the year of Greece's EMU membership qualification?\", 'What act spurred to building of new churches in Britain?', 'What is the cost of R/O produced water?', 'What extras does Windows 8 Pro have?', 'How many minor political parties are there?', 'When did electric street lights replace the gas operated lights?', 'What music did post-punk end to reject?', 'Where does the herpes virus hide?', 'When was the capital of Armenia established?', 'What year was peripheral pattern theory developed? ', 'In what month was the inaugural concert held for the \"Ed in \\'08\" campaign?', 'What year was the discovery of hydrogen gas?', 'What was the small vaulted room in the Great Palace of Constantinople called?', 'How is graphics information read from a CD+ Graphics?', 'When did the Declaration of Delhi happen?', 'Who instructs vehicles on which taxiways to use?', 'How many Jews settled into Palestine?', 'What company introduced the first HD video conferencing system to the general market?', 'Who is the head of the Washington University Athletic Department?', \"What is different about Chopin's waltzes versus a ballroom waltz?\", 'What day of the week did Churchill and the King meet?', 'What magazine described Portugal as \"a new sick man of Europe?\"', 'What suggested use for the river bed was rejected?', 'When did RCA release the 45?', 'What is thought to have played a significant role in the extinction of the Australian megafauna?', 'Hoe similar is Catalan to Portuguese?', \"A mammal's brain is how many times larger than a birds relative to body size?\", 'Which articles allow the soverign to refise consent even when the bills have been passed through the Legislative assembly?', 'How many certified albums does Madonna have?', 'What is the landscape of Eichsfeld? ', 'What happened to the Bishops who did not take the oath?', 'During what time period do some researchers believe Russians settled in Alaska?', 'What is the Edo period also known as?', 'Who owns The Daily Northwestern?', 'What percentage of the Swazi population are Christian?', \"Who is the Australian Party's deputy leader?\", 'The bill from the Australian House of Representatives was mistakenly sent and assented to by whom in 1976?', 'Who called for the sanctions in Burma to be given reprieve ?', 'What does the eel of the Tuvalu creation myth represent?', 'Portugese and British troops fought against the invasion of which country?', 'The Prime Minister is elected by who?', 'The ethnic groups Malays & Chinese are predominant in which country?', \"What months do the cheetah's avoid the sun?\", 'What are smaller insectivorous birds referred to?', 'Who uses the FBI lab services?', 'What religion was suppressed in Libya?', 'The end of what road was once home to Newgate Prison?', 'Who led the group which created the Soviet state?', 'What type of music does Kraftwerk make?', 'Why could the Tories and the Opposition Whigs never form a single party?', 'Why is sequencing done on plants?', 'When was the state run Nehru Government Engineering College started?', 'What country has the largest number of native Portuguese speakers?', 'What was the store in Sydney called after Jones moved to Australia? ', 'What is an opera buffa?', 'If the central banks can come to an agreement with the eurozone member about the continued repayment of the debt, what happens to the bad or weak debt?', 'When did the American War of Independence turn into a global conflict?', 'What type of religion is Buddhism?', \"Atlantic City's tourism began to decline due to what failure?\", 'On what date was a study created to research the impart of women in direct involvement?', 'What is Oklahoma Cities newsweekly?', 'Who is generally the audience favorite? ', 'What would the Federal Reserve buy to try and increase money supply?', 'What English popular revolt took place during this period?', 'What type of annual competition takes place during Kanavel?', 'What is the most populous city in Texas?', 'Automobile transportation is primarily used in what areas of London?', 'What kind of environment is the Pacific Northwest?', \"Who was Apollo's sister?\", 'When was independence declared?', 'What computer language came about as a result of the looping problem?', 'What simple word does the term szlachta translate too?', 'What is a contagious disease a subset of?', \"What towns had chosen Hannibal's side?\", 'Why did pre or prije develop rather than the symboled \"pre\"?', 'How strong was the powerful earthquake that hit Mexico City in 1985?', 'How many students attend the business school at KU?', 'Who directed The Terminator?', 'What will be created in the medieval triforium?', 'Who is a projecting Lady Chapel dedicated to?', 'Which magazine stated that Madonna was the greatest songwriter of all time?', 'Who taught indigenous scribes to write their languages?', 'When Malloy reached the end of his time as president how much annuals funding for research did Notre Dame have?', 'When did the Gempei War begin?', 'What is the method called that mixes red, green, and blue colors to form white light?', 'What is Somerset an important supplier of ', 'Of what language group is the Marshallese language?', 'What is the largest consumer of insects?', 'What is the Arabic term for the surface-level aspects of a text?', \"Where is Wayne County's Probate Court located?\", 'Who won the 1931 election?', 'Beginning in what century was the Book of Concord a central part of the Lutheran Church?', 'What is still a major symbol of Portuguese football history?', 'What makes the Windows 8 interface difficult to use?', 'Beyonce does not create which aspect of her music?', 'What species of hardwood are hickory and mulberry trees?', 'Who took 4 East India ship and arrested their officers as a reaction to the attack on Ganj-i-Sawai', 'What organization has said that there is no historical connection to association football with any other game outside of Europe?', '181st Street runs through what neighborhood?', 'In what decade did Europeans first visit the Marshall Islands?', 'Who discovered non-radio uses for early LED devices?', 'What is defined as the kinetic energy minus the potential energy?', 'How long has the single congressional district been Republican?', 'What did the island have an abundance of when discovered?', 'What is the interpretation of classical  of Samkhya?', 'What concept did Ledoux address?', 'How many Italians lived in Libya prior to October of 1970?', 'Where did the children go to work primarily in Switzerland?', 'What did Enlightenment scholars seek to curtail and thereby prevent another age of intolerant religious war?', 'How many big rivers flow through Thuringia? ', 'What architectural style was Westminster Abbey rebuilt in?', 'Who did Richard II of England marry?', \"What document established Manhattan's numbered street grid?\", \"How does emotional speech processing determine a user's emotional state?\", 'What results from possession by even benign spirits?', 'Charged ions can be used to produce what in glass?', 'In what century did the Pan-Germanisms origins begin?', 'Along with nitric acids, what acids dissolve uranium?', 'How were flutes constructed by the Native Americans?', 'What does soluble fiber do to help lower blood glucose levels?', 'In what year did they partner in order to do so?', \"Since which year has Tennessee's 1st congressional district voted overwhelmingly Republican?\", 'The tabs on the user interface were called what?', 'What is Vedic Sanskrit meant to be used as?', 'What is part of I-76 called?', 'In what century did Plymouth cease to be a vital trading port?', 'What is one method to protect the rights of the component states?', 'Kanye participated alongside Mike Meyers in a relief benefit show for what natural disaster?', 'What discipline uses infrared telescopes to see through molecular clouds?', 'What branch does the United States want to limit under the federalist model? ', 'How many servicemen and women were educated as a result of the GI Bill?', 'When was Shania Twain a guest judge for auditions?', 'What does \"open mouth operations\" mean?', \"What shifted attention away from the coverage regarding Bush's controvery regarding his required service?\", 'What element makes up about 6% of the chemical composition of wood?', 'With battle at Metz, what factor shattered the efforts of III Corps?', 'Which European ancestries are most common among self-identified ethnic \"Americans\" in Tennessee?', 'What factor were the French unaware of at the start of the battle?', \"What was the inaugural year of the New Haven St. Patrick's Day parade?\", 'What did Hong Kong Alliance in Support of Patriotic Democratic Movements in China members wave to symbolize democracy?', \"Who wrote 'War and Peace'?\", 'When was the first Papal prounouncement against Freemasonry made?', 'What type of educational institutions are in the area, that Nanjing can brag about?', 'What is the name of the son of Chen Zheng?', 'What change in flow of the sea controlled the innovative baths at West Quay?', 'What are the QF-4 aircraft being replaced by the US Air Force? ', 'What date was the island discovered on?', 'Along with Warner Music Group, what top three record label is based in New York City?', 'What was the name of the album she released in 1983?', 'Who is the 1855 Room named after?', \"What's the abbreviation for a Technische Universität?\", 'What % of the population claimed social security benefits in 2006/7?', 'What new recovery options did Windows 8 implement?', 'What type of instruments were prominent in soft rock? ', 'What was the total worldwide energy consumption in 2012?', 'How much military aggression did Maria Theresa exert following the war?', \"What is any sign which is capable of distinguishing one business's product from another business's?\", 'Who was Nene?', 'Where was the August 30, 2008 quake?', 'What was the impact of the war on the wealth of Austria?', \"On what does Palermo's economy rely?\", 'When did the U.S. Sixth Army land on the eastern shore of Leyte?', 'What is the highest court in the judicial order?', 'What alliance defeated the German Empire in World War I?', \"Who's dressing gown was placed by her side?\", 'Who stopped the Russians from attacking Vidin?', 'What did the Sumerians map stars into?', 'What institution did Western countries refuse to recognize?', 'What is the total population of New Haven as reported by the U.S. Census Bureau in 2010?', 'What is a primary interest to prospective NPO employees?', 'Along with horses and camels, what animals were used by the postal service?', 'Due to advances in science and culture, what are the Magadha region empires considered to represent?', 'What two airways are most effected by asthma?', 'What professions normally have the highest risk of problems?', \"Name a soundtrack in the film Who's That Girl?\", 'What rate per minute did ground transmitters send?', 'In what year was the abstand and ausbau framework developed?', 'Who is Buckingham palace home to?', 'Where in Africa did the French have control? ', 'When did James Baker visit Albania as Secretary of State?', 'Who designed the Cathedral of Brasília?', 'Where is an important stopover location?', 'How many people can the Mayflower Theatre hold?', 'Where among US universities does Notre Dame rank?', 'Which city is so far the southernmost city to host the Olympic Games?', \"What was Fantasia's coronation song?\", 'The demise of what left considerable confusion as to what was to be meant by \"Near East\" ', 'Who has to rely on nutrition experts when it comes to making decisions regarding food and nutritional values?', 'About how many Somalis live in the UK?', 'Name the main airport?', 'What type of diviners did the armies use to determine the will of the gods?', 'What type of influence of the Atlantic Ocean makes the temperatures fluctuate more than on the coast?', 'Which person portrayed Knute Rockne in the 1940 movie \"Knute Rockne?\"', 'What does the M. tuberculosis bacterium have that protects it from being affected by toxins?', 'What is a distinct trait of Synapsids?', 'What type of rhythmic figures are performed by the drummers playing the tamboril?', 'How many African slaves did Britain transport to the Americas?', 'What is a possible alternative to making carbon-based fuels from reduction of carbon dioxide?', 'Which role did Charles Sheedy have at Notre Dame?', 'When did Musharraf arrest Maulana Masood Azhar?', 'What is the street that is named after Juan Rodriguez?', 'What group was Nigeria a founding member of?', 'In Czech, what are loanwords from other languages associated with?', 'Which designer did Queen Mary work with to enhance the Centre Room?', 'What treaty was signed in 1936?', 'In 1958, what did the Middle Congo change its name to?', 'Which Armenian football team was the most successful?', 'What are at the ends of the ropes to help the gymnists hold it?', 'What platform was launched in Aug of 2015?', 'Do many cultures place value of the education of a young girl?', 'How much does a Samba costume typically run an average tourist to buy?', 'Who suggested that humankind does not exist inside time, but is time?', 'Parque Batlle is named in honor of who?', 'What actions caused the decline of the Mughal Empire?', 'What are feminist anthropologists centrally concerned about?', 'Who holds the legislative power?', 'The last census in Mexico that asked for race was carried out in which year?', 'For what reason would solar energy be used in a water stabilisation pond?', 'What percentage of marine life died during the extinction?', 'What type of clothing do doctors wear to protect their surroundings?', 'What common element do mosaic panels from the 11th century have?', 'What did Kerry think cost him the race against Cronin?', 'How many tourists visited NYC in 2013?', 'How many people lost jobs when Beyonce left the video game deal?', 'Whose philosophy gave much to Christian thought of the time?', 'What style of music does Beyoncé usually perform?', 'When was the Air Commerce Act passed?', 'What record format was created for use in Chrysler automobiles?', 'What is the mother of a litter referred as?', \"What studio's case decision was NOT overturned?\", 'What is the generic term for an airplane or rocket in French?', 'What word additive is usually added to verbs?', 'What other group has also been under this integrated command and control?', 'Who was in charge of the Russian Caucasus Army of Imperial forces?', 'How do regulatory regions on different chromosomes operate in order to allow regions on different chromosomes to come into contact with one another?', 'When was the Title King of the Germans first used?', 'What is more important for law enforcement in categorizing instead of DNA?', 'What possession did the French lose to the Brits in 1758', 'What was the name of the document that standardized Serbo-Croatian?', 'What formerly effective tool for international disputes is no longer effective among peer powers?', 'When did Namibia obtain full independence?', 'How many mass extinctions have happened since Life began on Earth?', 'What subject is arguable concerning Tuvalu?', 'What month did the capture of Malakoff take place?', 'What kind of geologic activity occurred during the Mesozoic?', 'The border territories assigned to the United Provinces were known as what?', 'Rosemary  Goring connected Lee to whom?', \"What is Nigeria's 2015 purchasing power parity?\", 'Which agency is in charge of health and wellness services in Hyderabad?', 'When the Oklo mine ore deposits came into being, what percentage of uranium on Earth consisted of uranium-235?', 'Which type of cells in the brain are generated throughout your lifetime?', 'How much more water should pregnant women consumed compared to an average non - pregnant woman?', 'How many hospitals does it manage?', 'The winners of World War II along with France were allotted permanent seats for what organization?', 'What was the export level of Sichuan in 2008?', 'What is responsible for different dog types and breeds today?', 'Who in the MoD was convicted of fraud?', 'Who worked towards obtaining a extension of relations with Tibet?', 'What is a popular name for the Telugu film industry?', 'What is the term for the strategies used by people to influence their emotional experiences?', 'In what part of the world did the fictional detective, Nero Wolfe, live in?', 'Where did Japan open a military school in 1855?', 'In what year did cardinals in the Roman Catholic church start wearing red?', 'Along with the USPS, what United States agency operates in the Marshall Islands?', 'How much did it cost each company for the first season?', 'What are often called psychoacoustic models?', 'The first woman to launch into space was on what date?', 'What republic had the Karachay Autonomous Oblast previously been a part of?', 'What vegetable features in the Tuvalu diet?', 'Was there ever an official peace treaty after the war?', 'Where is Fenway park?', \"From what other country's orthography did the Older Orthography get its basis?\", \"How much of the Bronx's vote in 1916 did Hughes get?\"]\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "# Initialize the tokenizer from the pre-trained BERT model\n",
        "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased', use_fast=True)\n",
        "\n",
        "max_len = max(max_len_context, max_len_que)\n",
        "max_start_pos=0\n",
        "max_pos = 0\n",
        "def preprocess_data(examples):\n",
        "    # Tokenize the input texts and get the offsets mapping\n",
        "    tokenized_inputs = tokenizer(\n",
        "        examples['question'],\n",
        "        examples['context'],\n",
        "        truncation=True,\n",
        "        max_length=max_len,\n",
        "        return_offsets_mapping=True,\n",
        "        return_tensors='np'  \n",
        "    )\n",
        "\n",
        "    start_positions = []\n",
        "    end_positions = []\n",
        "\n",
        "    for i, offsets in enumerate(tokenized_inputs['offset_mapping']):\n",
        "        # Initialize default positions for cases where the answer is not found\n",
        "        start_token, end_token = 0, 0\n",
        "\n",
        "        # Only proceed if an answer exists\n",
        "        if examples['answers'][i]['answer_start'] and examples['answers'][i]['text']:\n",
        "            start_char = examples['answers'][i]['answer_start'][0]\n",
        "            end_char = start_char + len(examples['answers'][i]['text'][0])\n",
        "\n",
        "            for idx, (offset_start, offset_end) in enumerate(offsets):\n",
        "                if start_token == 0 and start_char >= offset_start and start_char < offset_end:\n",
        "                    start_token = idx\n",
        "                if end_char > offset_start and end_char <= offset_end:\n",
        "                    end_token = idx\n",
        "                    break  # Stop once the end token is found\n",
        "        max_start_pos=max(end_token,max_pos)\n",
        "        # print(start_token, end_token)\n",
        "        start_positions.append(start_token)\n",
        "        end_positions.append(end_token)\n",
        "\n",
        "    tokenized_inputs.pop('offset_mapping')\n",
        "\n",
        "    # Convert lists to arrays to store in the Hugging Face dataset\n",
        "    tokenized_inputs['start_positions'] = np.array(start_positions)\n",
        "    tokenized_inputs['end_positions'] = np.array(end_positions)\n",
        "\n",
        "    return tokenized_inputs\n",
        "\n",
        "\n",
        "\n",
        "# Apply the preprocessing function to the dataset\n",
        "print(dataset)\n",
        "\n",
        "tokenized_datasets = dataset.map(preprocess_data, batched=True)\n",
        "print(tokenized_datasets)\n",
        "print(tokenized_datasets['train']['answers'])\n",
        "\n",
        "print(tokenized_datasets['train']['question'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QrpRNVd2XZFl",
        "outputId": "fa1c982d-76e5-4caf-fd5d-b9033b489466"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "400000\n",
            "torch.Size([30522, 200])\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "vocab_size = len(tokenizer.vocab)  # Assuming you have a tokenizer\n",
        "print(len(glove))\n",
        "# embedding_dim = len(next(iter(glove.values())))  # Dimension of GloVe vectors\n",
        "# embedding_dim = e\n",
        "# Initialize the embedding matrix\n",
        "embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
        "\n",
        "\n",
        "for word, idx in tokenizer.vocab.items():\n",
        "    # vector = glove.get(word)\n",
        "    if word in glove:\n",
        "        embedding_matrix[idx] = glove[word]\n",
        "    else:\n",
        "        # If the word is not in GloVe, initialize with random values\n",
        "        embedding_matrix[idx] = np.random.normal(scale=0.6, size=(embedding_dim, ))\n",
        "\n",
        "# Convert the matrix to a torch tensor\n",
        "embedding_matrix = torch.tensor(embedding_matrix, dtype=torch.float)\n",
        "print(embedding_matrix.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "agJMRCqlLSdk"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "class QuestionAnsweringDataset(Dataset):\n",
        "    def __init__(self, questions, contexts, start_positions, end_positions, tokenizer):\n",
        "        self.questions = questions\n",
        "        self.contexts = contexts\n",
        "        self.start_positions = start_positions\n",
        "        self.end_positions = end_positions\n",
        "        self.tokenizer = tokenizer\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.questions)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        question = self.questions[idx]\n",
        "        context = self.contexts[idx]\n",
        "        start_position = self.start_positions[idx]\n",
        "        end_position = self.end_positions[idx]\n",
        "\n",
        "        question_encodings = self.tokenizer(question, return_tensors='pt', padding='max_length', truncation=True, max_length=max_len_que+1)\n",
        "        context_encodings = self.tokenizer(context, return_tensors='pt', padding='max_length', truncation=True, max_length=max_len_context+1)\n",
        "\n",
        "        return {\n",
        "            'question_ids': question_encodings['input_ids'].squeeze(0),  # Remove batch dimension\n",
        "            'question_mask': question_encodings['attention_mask'].squeeze(0),\n",
        "            'context_ids': context_encodings['input_ids'].squeeze(0),\n",
        "            'context_mask': context_encodings['attention_mask'].squeeze(0),\n",
        "            'start_positions': torch.tensor(start_position, dtype=torch.long),\n",
        "            'end_positions': torch.tensor(end_position, dtype=torch.long)\n",
        "        }\n",
        "\n",
        "# Assuming `questions`, `contexts`, `start_positions`, `end_positions` are lists containing your data\n",
        "# print(tokenized_datasets)\n",
        "questions = tokenized_datasets['train']['question']\n",
        "contexts = tokenized_datasets['train']['context']\n",
        "start_positions = tokenized_datasets['train']['start_positions']\n",
        "end_positions = tokenized_datasets['train']['end_positions']\n",
        "\n",
        "dataset = QuestionAnsweringDataset(questions, contexts, start_positions, end_positions, tokenizer)\n",
        "# print(dataset[0])\n",
        "# Create a DataLoader\n",
        "loader = DataLoader(dataset, batch_size=32, shuffle=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3hVnzfIZqbP2"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DlvSCBAjI_wb",
        "outputId": "4de71f0c-d900-4e17-ee00-eb5d897fa125"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "30522\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/manav/.local/lib/python3.8/site-packages/torch/cuda/__init__.py:141: UserWarning: CUDA initialization: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)\n",
            "  return torch._C._cuda_getDeviceCount() > 0\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
        "\n",
        "class QuestionAnsweringModel(nn.Module):\n",
        "    def __init__(self, hidden_size, vocab_size, embed_size,embedding_matrix, dropout_rate=0.2):\n",
        "        super(QuestionAnsweringModel, self).__init__()\n",
        "        self.embedding = nn.Embedding.from_pretrained(embedding_matrix, freeze=True)\n",
        "        self.question_bilstm = nn.LSTM(embed_size, hidden_size, batch_first=True, bidirectional=True)\n",
        "        self.context_bilstm = nn.LSTM(embed_size, hidden_size, batch_first=True, bidirectional=True)\n",
        "\n",
        "        # This layer will transform the context to have the same size as the question for attention\n",
        "        self.attention_layer = nn.Linear(hidden_size * 2, hidden_size * 2)\n",
        "\n",
        "        self.decoder_bilstm = nn.LSTM(hidden_size * 4, hidden_size, batch_first=True, bidirectional=True)\n",
        "        self.output_layer = nn.Linear(hidden_size * 2, 1)  # Output 2 scores for each token, start and end logits\n",
        "        self.dropout = nn.Dropout(dropout_rate)\n",
        "\n",
        "    def forward(self, question_ids, question_mask, context_ids, context_mask):\n",
        "        question_embedded = self.dropout(self.embedding(question_ids))\n",
        "        context_embedded = self.dropout(self.embedding(context_ids))\n",
        "\n",
        "        # Question encoding\n",
        "        packed_question = pack_padded_sequence(question_embedded, question_mask.sum(1).cpu(), batch_first=True, enforce_sorted=False)\n",
        "        question_output, _ = self.question_bilstm(packed_question)\n",
        "        question_output, _ = pad_packed_sequence(question_output, batch_first=True)\n",
        "\n",
        "        # Context encoding\n",
        "        packed_context = pack_padded_sequence(context_embedded, context_mask.sum(1).cpu(), batch_first=True, enforce_sorted=False)\n",
        "        context_output, _ = self.context_bilstm(packed_context)\n",
        "        context_output, _ = pad_packed_sequence(context_output, batch_first=True)\n",
        "\n",
        "        # Apply attention\n",
        "        attn_scores = torch.bmm(context_output, self.attention_layer(question_output).transpose(1, 2))\n",
        "        attn_weights = F.softmax(attn_scores, dim=-1)\n",
        "        attended_question = torch.bmm(attn_weights, question_output)\n",
        "\n",
        "        # Concatenate context and attended question for each token\n",
        "        combined_output = torch.cat((context_output, attended_question), dim=-1)\n",
        "\n",
        "        # Decode\n",
        "        decoder_output_start, _ = self.decoder_bilstm(combined_output)\n",
        "        decoder_output_end, _ = self.decoder_bilstm(combined_output)\n",
        "\n",
        "        # Get start and end logits\n",
        "        start_logits = self.output_layer(decoder_output_start)\n",
        "        end_logits = self.output_layer(decoder_output_end)\n",
        "        # print(start_logits.shape, end_logits.shape)\n",
        "\n",
        "        # start_logits, end_logits = logits.split(1, dim=-1)\n",
        "\n",
        "        return start_logits.squeeze(), end_logits.squeeze()\n",
        "\n",
        "# Define sizes\n",
        "hidden_size = 256\n",
        "vocab_size = len(tokenizer)  # Assume tokenizer is defined elsewhere\n",
        "print(vocab_size)\n",
        "embed_size = embedding_dim\n",
        "\n",
        "# Device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "# device = torch.device(\"cpu\")\n",
        "\n",
        "# Initialize the model\n",
        "model = QuestionAnsweringModel(hidden_size, vocab_size, embed_size, embedding_matrix=embedding_matrix).to(device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kaUGbEpeK6kn",
        "outputId": "1309a81a-f775-4b73-f7a6-c2e2325c9cca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0 5.231\n",
            "1 3.522\n",
            "2 2.541\n",
            "3 1.978\n",
            "4 1.656\n",
            "5 1.47\n",
            "6 1.364\n",
            "7 1.303\n",
            "8 1.268\n",
            "9 1.248\n"
          ]
        }
      ],
      "source": [
        "from torch.optim import Adam,SGD\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.nn.utils import clip_grad_norm_\n",
        "\n",
        "# Prepare the DataLoader\n",
        "\n",
        "\n",
        "# Initialize optimizer\n",
        "optimizer = Adam(model.parameters(), lr=0.001)\n",
        "# optimizer = SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "train_loader=loader\n",
        "model.train()\n",
        "max_grad_norm = 1.0\n",
        "num_epochs = 10\n",
        "epoch_losses = []\n",
        "for epoch in range(num_epochs):  # Example for 3 epochs\n",
        "    epoch_loss = 0\n",
        "    for batch in train_loader:\n",
        "        # print(batch)\n",
        "        question_ids = batch['question_ids'].to(device)\n",
        "        question_mask = batch['question_mask'].to(device)\n",
        "        context_ids = batch['context_ids'].to(device)\n",
        "        context_mask = batch['context_mask'].to(device)\n",
        "        start_positions = batch['start_positions'].to(device)\n",
        "        end_positions = batch['end_positions'].to(device)\n",
        "\n",
        "        # input_ids = torch.tensor(input_ids)\n",
        "        # attention_mask = torch.tensor(attention_mask)\n",
        "        optimizer.zero_grad()\n",
        "        # attetntion\n",
        "        # print(input_ids.shape, attention_mask)\n",
        "        # print(question_ids.shape, question_mask.shape, context_ids.shape, context_mask.shape)\n",
        "        start_logits, end_logits = model(question_ids, question_mask, context_ids, context_mask)\n",
        "        # start_logits=start_logits.T\n",
        "        # end_logits=end_logits.T\n",
        "\n",
        "        ten= torch.tensor(start_logits.shape[1]-1)\n",
        "        start_positions =torch.minimum(start_positions, ten)\n",
        "        start_loss = nn.CrossEntropyLoss()(start_logits, start_positions)\n",
        "        ten = torch.tensor(end_logits.shape[1]-1)\n",
        "        end_positions =torch.minimum(end_positions, ten)\n",
        "\n",
        "        end_loss = nn.CrossEntropyLoss()(end_logits, end_positions)\n",
        "        loss = (start_loss + end_loss)/2\n",
        "\n",
        "        epoch_loss+=loss.item()\n",
        "        loss.backward()\n",
        "        clip_grad_norm_(model.parameters(), max_grad_norm)\n",
        "\n",
        "        optimizer.step()\n",
        "    epoch_losses.append(epoch_loss)\n",
        "    print(epoch,epoch_loss)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmEAAAGDCAYAAABjkcdfAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy88F64QAAAACXBIWXMAAAsTAAALEwEAmpwYAAA3ZElEQVR4nO3debwWdd3/8deHRRBwBSUVgcql1NwgtcwUrPROszLXUNNU0swUM60su73LO9s0l6xMTVMMt1xuK1sUNVs0NDC3zBTct1yPKCJ8fn/MdX4cDufgQc5cc10Xr+fjMY8z18ycmc/3HIU33/nOdyIzkSRJUn31qboASZKkZZEhTJIkqQKGMEmSpAoYwiRJkipgCJMkSaqAIUySJKkChjBJahIRMToiMiL6VV2LpKVnCJO0VGqhYJ2Krr1zRNwaES9HxH8iYnJEjKjj9bN27bYOyzH1ur6k5mYIk9SUImI34CLgB8AwYENgDnBzRKzSy9daXM/TJpk5pMPynd68tqTWZQiTVIqIWCkifh4RT0fErIj4akT0qe1bJyJujIgXIuKZiLi4tj0i4pSIeCoiXoyIf0TERl2cO4DvA9/MzIsy85XMfAI4CGgDJkXEgIh4vuP3R8RqEfFKRKxe+7xzREyvHffniNi4w7EzI+LYiLgDeHlJbwFGxH9HxGURcXFEvBQRt0fEJh32vzMibqhd+66I2KXDvuUj4vu1n9sLEXFzRCzf4fQTIuKh2s/uuA7ft0VETKv97J6MiJOXpGZJ9WUIk1SW04GVgLcB2wL7AQfU9n0D+B2wCjCidizAh4D3A+vVvncP4D9dnHt9YCRwaceNmTkfuBz4YGbOAX4J7N3hkD2AGzPzqYjYDDgX+AwwFPgJcHVEDOhw/N7ATsDKmfn6ErYf4KO1Glel6LW7MiL6R0R/4P9qP4PVgcOByRGxfu37vgeMAd5b+95jgPkdzvu+2s9ge+D4iHhnbfupwKmZuSLwduCSN1GzpDoxhEnqdRHRF9gL+HJmvpSZMyl6rvatHTIXGAWsmZmvZubNHbavALwDiMy8JzMf7+ISw2pfu9r3eIf9F9XqaPfJ2jaAicBPMvOWzJyXmedT3M7cqsPxp2Xmw5n5ymKae3utN6t92aHDvtsy87LMnAucDAysnX8rYAhwUma+lpnXA9cAe9d6Cz8NHJGZj9Zq+3MtVLY7odb7NwOYAbT3sM0F1omIYZnZlpl/XUzdkipmCJNUhmFAf2BWh22zgLVq68cAAdxauxX3aYBaGDkD+CHwVEScFRErdnH+Z2pf1+hi3xod9k8FBkXElhExGtgUuKK2bxTwhY4BClgbWLPDuR7uQVs3z8yVOyy/7er7a710j9TOvybwcG1bu/afzzCKsPbvxVzziQ7rsykCHcCBFL2I90bE3yJi5x7UL6kihjBJZXiGBb1d7UYCjwJk5hOZeXBmrklxO/DM9icsM/O0zBwDbEARKL7Yxfn/SRFodu+4sdaL9Angutq55lHcktu7tlyTmS/VDn8YOLFTgBqUmb/ocMp80z+BwtqdahsBPFZb1m4fI1fT/vN5BniV4nbiEsnMf2Xm3hS3OL8NXBYRg998+ZLKZAiT1BuWi4iB7Utt2yXAiRGxQkSMAo4CLgSIiN07TCXxHEXYmR8R7671WvUHXqYII/PpJDMTOBr4akR8snbdtwBnAysCp3Q4/CJgT2ACC25FAvwUOKR2vYiIwRGxU0Ss0Cs/kcKYiNi1Nqj/SIrbnX8FbqHowTqmNkZsO+AjwJRa79i5wMkRsWZE9I2I93Qaq9aliNgnIlarneP52uZFfn6SGoMhTFJvuAt4pcNyAMVg85eBB4CbKQLQubXj3w3cEhFtwNUU458eoAhQP6UIZrMoBuV/t6sLZubFFGPMJtWOuxtYHtg6M//T4bhbanWsCfymw/ZpwMEUtz+fA+4H9n8TbZ8RC88T9oMO+66iCIDP1WrdNTPnZuZrFKHrvyh6vs4E9svMe2vfdzTwD+BvwLMUvVo9+fN6R+Cu2s/1VGCvNxjPJqlCUfyDUpLUmyLiv4F1MnOfqmuR1JjsCZMkSaqAIUySJKkC3o6UJEmqgD1hkiRJFTCESZIkVWCJXkjbCIYNG5ajR48u/Tovv/wygwe37hyHtq/5tXobbV/za/U22r7mV4823nbbbc9k5mpd7Wu6EDZ69GimTZtW+nVuuOEGtttuu9KvUxXb1/xavY22r/m1ehttX/OrRxsjYlZ3+7wdKUmSVAFDmCRJUgUMYZIkSRUwhEmSJFXAECZJklQBQ5gkSVIFDGGSJEkVMIRJkiRVwBAmSZJUAUNYJ5Mnw+jRMH78toweXXyWJEnqbU332qIyTZ4MEyfC7NkAwaxZxWeACROqrEySJLUae8I6OO649gC2wOzZxXZJkqTeZAjr4KGHlmy7JEnSm2UI62DkyCXbLkmS9GYZwjo48UQYNGjhbYMGFdslSZJ6kyGsgwkT4Kyz2nu+koEDi88OypckSb3NENbJhAkwaxYcdNCDvPoqbLJJ1RVJkqRWZAjrxkc+8hiDBsEpp1RdiSRJakWGsG6suOLrfOpTxdxhTz5ZdTWSJKnVGMIW44gjYM4c+NGPqq5EkiS1GkPYYqy/Puy8M5x5Jrz6atXVSJKkVmIIewOTJsHTT8NFF1VdiSRJaiWGsDcwblzxhOTJJ0Nm1dVIkqRWYQh7AxFFb9hdd8Ef/lB1NZIkqVUYwnpgr71g+PCiN0ySJKk3GMJ6YMAA+Nzn4Npr4e67q65GkiS1glJDWETMjIh/RMT0iJjWxf6IiNMi4v6IuCMiNi+znqVxyCEwcCD84AdVVyJJklpBPXrCxmXmppk5tot9/wWsW1smAg07I9ewYbDffnDBBfDMM1VXI0mSml3VtyM/Cvw8C38FVo6INSquqVtHHlnMF/bjH1ddiSRJanZlh7AEfhcRt0XExC72rwU83OHzI7VtDemd74Qdd4Qzzihm0pckSXqzIkuc/Coi1srMRyNideD3wOGZeVOH/dcAJ2XmzbXP1wHHZua0TueZSHG7kuHDh4+ZMmVKaTW3a2trY8iQIYtsnzZtFb74xU049th72HHH5n2pZHftaxWt3j5o/TbavubX6m20fc2vHm0cN27cbd0MySo3hC10oYj/Btoy83sdtv0EuCEzf1H7/E9gu8x8vLvzjB07NqdNW2SMf6+74YYb2G677RbZngkbbwx9+sD06cU8Ys2ou/a1ilZvH7R+G21f82v1Ntq+5lePNkZEtyGstNuRETE4IlZoXwc+BNzZ6bCrgf1qT0luBbywuADWCNonb73jDpg6tepqJElSsypzTNhw4OaImAHcCvwqM6+NiEMi4pDaMb8GHgDuB34KfLbEenrNJz8Jq68Op5xSdSWSJKlZ9SvrxJn5ALBJF9t/3GE9gcPKqqEsAwfCoYfCCSfAP/8J669fdUWSJKnZVD1FRdM69NBiJv1TT626EkmS1IwMYW/S8OEwYQKcdx785z9VVyNJkpqNIWwpTJoEr7wCZ51VdSWSJKnZGMKWwkYbwQc/WEze+tprVVcjSZKaiSFsKU2aBI89BpdcUnUlkiSpmRjCltIOOxSvMzrllGIiV0mSpJ4whC2lPn2KF3vffjvcdNMbHi5JkgQYwnrFvvvC0KFO3ipJknrOENYLll++mDfs6qvh/vurrkaSJDUDQ1gv+exnoV8/J2+VJEk9YwjrJWusUbxT8mc/g+eeq7oaSZLU6AxhvWjSJHj5ZfjpT6uuRJIkNTpDWC/aZBMYPx5OPx3mzq26GkmS1MgMYb1s0iR45BG4/PKqK5EkSY3MENbLPvxhWG89OPlkJ2+VJEndM4T1svbJW//2N/jzn6uuRpIkNSpDWAn22w9WWaXoDZMkSeqKIawEgwfDIYfAlVfCgw9WXY0kSWpEhrCSHHZYcWvytNOqrkSSJDUiQ1hJ1loL9twTzj4bXnih6mokSVKjMYSVaNIkaGuDc86puhJJktRoDGElGjMG3v/+4n2Sr79edTWSJKmRGMJKdtRR8NBDcMUVVVciSZIaiSGsZDvvDG9/O5xyStWVSJKkRmIIK1nfvnDEEfCXv8Bf/1p1NZIkqVEYwurggANgpZXsDZMkSQsYwupgyBCYOBEuuwxmzaq6GkmS1AgMYXVy+OEQAaefXnUlkiSpEZQewiKib0T8PSKu6WLf/hHxdERMry0HlV1PVdZeG3bfHX76U3jppaqrkSRJVatHT9gRwD2L2X9xZm5aW86uQz2VmTQJXnwRzj236kokSVLVSg1hETEC2Alo6XDVU1tsAVtvXUzeOm9e1dVIkqQqld0T9gPgGGD+Yo75RETcERGXRcTaJddTuUmT4MEH4aqrqq5EkiRVKTKznBNH7Ax8ODM/GxHbAUdn5s6djhkKtGXmnIj4DLBnZo7v4lwTgYkAw4cPHzNlypRSau6ora2NIUOG9Pp5582DffbZktVWm8Npp03v9fP3VFntaxSt3j5o/TbavubX6m20fc2vHm0cN27cbZk5tsudmVnKAnwLeASYCTwBzAYuXMzxfYEX3ui8Y8aMyXqYOnVqaec+5ZRMyLz11tIu8YbKbF8jaPX2ZbZ+G21f82v1Ntq+5lePNgLTsptMU9rtyMz8cmaOyMzRwF7A9Zm5T8djImKNDh93YfED+FvGpz8NK6zg5K2SJC3L6j5PWET8T0TsUvv4+Yi4KyJmAJ8H9q93PVVYcUU4+GC49FJ4+OGqq5EkSVWoSwjLzBuyNh4sM4/PzKtr61/OzA0zc5PMHJeZ99ajnkZw+OEwfz6ccUbVlUiSpCo4Y35FRo+GXXeFs86Ctraqq5EkSfVmCKvQUUfB88/DeedVXYkkSao3Q1iF3vMe2HLLYvLW+YubSU2SJLUcQ1jFjjoK7r8frlnkzZqSJKmVGcIqtuuuMHIknHxy1ZVIkqR6MoRVrF+/4knJG2+E22+vuhpJklQvhrAGcNBBMGSIk7dKkrQsMYQ1gJVXLmbRnzIFHnus6mokSVI9GMIaxBFHFC/3/uEPq65EkiTVgyGsQbztbfCxj8GPfwyzZ1ddjSRJKpshrIFMmgTPPgs//3nVlUiSpLIZwhrI+94HY8cWA/SdvFWSpNZmCGsgEUVv2H33wW9+U3U1kiSpTIawBrP77rDWWk5XIUlSqzOENZj+/YvJW6+7DmbMqLoaSZJUFkNYA5o4EQYNgh/8oOpKJElSWQxhDWiVVeCAA+Cii+CJJ6quRpIklcEQ1qCOOALmzoUzz6y6EkmSVAZDWINad134yEfgRz+CV16puhpJktTbDGENbNIkeOYZuPDCqiuRJEm9zRDWwLbdFjbdtJiuIrPqaiRJUm8yhDWwCDjqKLjnHvjtb6uuRpIk9SZDWIPbc09YYw0nb5UkqdUYwhrccsvB5z4Hv/sd3Hln1dVIkqTeYghrAp/5DCy/vJO3SpLUSgxhTWDoUNhvv+IpyaeeqroaSZLUGwxhTeLII2HOnGLeMEmS1PwMYU3iHe+AD3+4mEH/1VerrkaSJC0tQ1gTOeqo4nbkL35RdSWSJGlplR7CIqJvRPw9Iq7pYt+AiLg4Iu6PiFsiYnTZ9TSz8eNh442dvFWSpFZQj56wI4B7utl3IPBcZq4DnAJ8uw71NK2IYmzYP/4B111XdTWSJGlplBrCImIEsBNwdjeHfBQ4v7Z+GbB9RESZNTW7T34Shg+Hk0+uuhJJkrQ0Iku8rxURlwHfAlYAjs7MnTvtvxPYMTMfqX3+N7BlZj7T6biJwESA4cOHj5kyZUppNbdra2tjyJAhpV/nzTj//FGcd95bOe+8Wxk1avabOkcjt683tHr7oPXbaPuaX6u30fY1v3q0cdy4cbdl5tgud2ZmKQuwM3BmbX074JoujrkTGNHh87+BYYs775gxY7Iepk6dWpfrvBlPPZU5YEDmZz7z5s/RyO3rDa3evszWb6Pta36t3kbb1/zq0UZgWnaTacq8Hbk1sEtEzASmAOMj4sJOxzwKrA0QEf2AlYD/lFhTS1htNdh3Xzj/fHjmmTc+XpIkNZ7SQlhmfjkzR2TmaGAv4PrM3KfTYVcDn6qt71Y7xuf+euDII4v5wn7yk6orkSRJb0bd5wmLiP+JiF1qH88BhkbE/cBRwJfqXU+z2nBD2GEHOOOMYiZ9SZLUXOoSwjLzhqwNys/M4zPz6tr6q5m5e2auk5lbZOYD9ainVUyaBE88ARdfXHUlkiRpSTljfhP70Idggw2cvFWSpGZkCGtiEUVv2PTpcMMNVVcjSZKWhCGsyU2YAMOGFb1hkiSpeRjCmtzyy8NnPwv/939w331VVyNJknrKENYCPvtZWG45OPXUqiuRJEk9ZQhrAcOHF7clzzsPnn226mokSVJPGMJaxKRJMHs2nHVW1ZVIkqSeMIS1iHe9C7bfHk4/HV57repqJEnSGzGEtZCjjoLHHoNLL626EkmS9EYMYS1kxx1h/fWdvFWSpGZgCGshffoUY8Nuuw1uvrnqaiRJ0uIYwlrMvvvCqqvCySdXXYkkSVocQ1iLGTQIDjkErroK/v3vqquRJEndMYS1oMMOg379nLxVkqRGZghrQWuuCXvtBeeeC88/X3U1kiSpK4awFjVpErz8Mvz0p1VXIkmSumIIa1GbbQbbbVdM3vr661VXI0mSOjOEtbBJk+Dhh+Hyy6uuRJIkdWYIa2E77wzrrFNMV+HkrZIkNRZDWAvr0weOPBJuvRX+8peqq5EkSR0Zwlrc/vvDKqs4easkSY3GENbiBg+GiRPhiivgwQerrkaSJLUzhC0DPve54tbk6adXXYkkSWpnCFsGjBgBe+wBZ58NL75YdTWSJAkMYcuMSZPgpZfgnHOqrkSSJIEhbJkxdixss03xPkknb5UkqXqGsGXIpEkwaxZceWXVlUiSJEPYMmSXXWC11WCffWD8+G0ZPRomT666KkmSlk2lhbCIGBgRt0bEjIi4KyJO6OKY/SPi6YiYXlsOKqsewZQp8PzzMGcOZAazZhXTVxjEJEmqvzJ7wuYA4zNzE2BTYMeI2KqL4y7OzE1ry9kl1rPMO+44mDt34W2zZxfbJUlSffUr68SZmUBb7WP/2uIbDCv00ENLtl2SJJUnssQ3O0dEX+A2YB3gh5l5bKf9+wPfAp4G7gMmZebDXZxnIjARYPjw4WOmTJlSWs3t2traGDJkSOnXqae99tqKJ58cuMj24cNfZcqUv1ZQUXla8ffXWau30fY1v1Zvo+1rfvVo47hx427LzLFd7szM0hdgZWAqsFGn7UOBAbX1zwDXv9G5xowZk/UwderUulynni68MHPQoExYeDn11Kor632t+PvrrNXbaPuaX6u30fY1v3q0EZiW3WSaujwdmZnP10LYjp22/ycz59Q+ng2MqUc9y6oJE+Css2DUKIhI1lwTBgyAiy6C116rujpJkpYtZT4duVpErFxbXx74IHBvp2PW6PBxF+CesupRYcIEmDkTrr/+Rh59FC68EG65Bb7whaorkyRp2VJmT9gawNSIuAP4G/D7zLwmIv4nInapHfP52vQVM4DPA/uXWI+6sNtuxSSuZ5xR9IhJkqT6KPPpyDuAzbrYfnyH9S8DXy6rBvXMt78Nt94KBx8Mm2wCG25YdUWSJLU+Z8wX/fvDJZfAkCHwiU8UL/qWJEnlMoQJgDXXLGbU/9e/4MADi+cmJUlSeQxh+v/GjYP//V+49FI47bSqq5EkqbUZwrSQY44pXvR99NHwpz9VXY0kSa3LEKaFRMD558PIkbDHHvDUU1VXJElSa+pRCIuIwRHRp7a+XkTsEhH9yy1NVVl5Zbj8cnj2WdhrL3j99aorkiSp9fS0J+wmYGBErAX8DtgXOK+solS9TTeFM8+EqVPh+OPf8HBJkrSEehrCIjNnA7sCZ2bm7oCzSbW4Aw6Agw6Cb30Lrr666mokSWotPQ5hEfEeYALwq9q2vuWUpEZy+umw+eaw337wwANVVyNJUuvoaQg7kmJm+ysy866IeBvFC7nV4gYOhMsuKwbsf+IT8MorVVckSVJr6FEIy8wbM3OXzPx2bYD+M5n5+ZJrU4N461vhggtg+nQ4/PCqq5EkqTX09OnIiyJixYgYDNwJ3B0RXyy3NDWSnXeG446Dc84pFkmStHR6ejtyg8x8EfgY8BvgrRRPSGoZcsIJsP32cNhh8Pe/V12NJEnNrachrH9tXrCPAVdn5lzAtwsuY/r2hYsugmHDYLfd4Lnnqq5IkqTm1dMQ9hNgJjAYuCkiRgEvllWUGtfqqxfvlnzoIfjUp2D+/KorkiSpOfV0YP5pmblWZn44C7OAcSXXpgb1nvfA978P//d/8O1vV12NJEnNqacD81eKiJMjYlpt+T5Fr5iWUYcfDnvuCV/9Klx/fdXVSJLUfHp6O/Jc4CVgj9ryIvCzsopS44uAs8+G9dYr3i/56KNVVyRJUnPpaQh7e2Z+PTMfqC0nAG8rszA1viFDihd9z54Ne+wBc+dWXZEkSc2jpyHslYh4X/uHiNgacO50scEGRY/Yn/8MxxxTdTWSJDWPfj087hDg5xGxUu3zc8CnyilJzWavvYoQ9oMfFIP299ij6ookSWp8PX06ckZmbgJsDGycmZsB40utTE3le9+DrbaCAw+Ee++tuhpJkhpfT29HApCZL9Zmzgc4qoR61KSWW66YP2zgwOJF321tVVckSVJjW6IQ1kn0WhVqCSNGwC9+AffcAxMnQvpOBUmSurU0Icy/YrWID3wAvvGNIoydeWbV1UiS1LgWOzA/Il6i67AVwPKlVKSm9+Uvw1/+ApMmwZgxxVgxSZK0sMX2hGXmCpm5YhfLCpnZ0ycrtYzp0wcuuADWWgt23x2efrrqiiRJajxLcztS6tYqq8BllxUBbMIEmDev6ookSWospYWwiBgYEbdGxIyIuCsiTujimAERcXFE3B8Rt0TE6LLqUf2NGQNnnAG//z2csMhvX5KkZVuZPWFzgPG1+cU2BXaMiM6jgw4EnsvMdYBTgG+XWI8qcOCBsP/+xWD9X/+66mokSWocpYWwLLTPFtW/tnQe5P9R4Pza+mXA9hHh1BctJAJ++EPYZBPYZx+YObPqiiRJagyljgmLiL4RMR14Cvh9Zt7S6ZC1gIcBMvN14AVgaJk1qf4GDSrGh82fD7vtBq++WnVFkiRVL7IOM2pGxMrAFcDhmXlnh+13Ajtm5iO1z/8GtszMZzp9/0RgIsDw4cPHTJkypfSa29raGDJkSOnXqUoV7bv55qF87Wvv4iMfeYyjjrqv1Gu1+u8PWr+Ntq/5tXobbV/zq0cbx40bd1tmju1yZ2bWZQGOB47utO23wHtq6/2AZ6gFw+6WMWPGZD1MnTq1LtepSlXtO/bYTMg8//xyr9Pqv7/M1m+j7Wt+rd5G29f86tFGYFp2k2nKfDpytVoPGBGxPPBBoPOrna8GPlVb3w24vlawWtQ3vwnbbQeHHAJ33FF1NZIkVafMMWFrAFMj4g7gbxRjwq6JiP+JiF1qx5wDDI2I+yleCP6lEutRA+jXr3il0corFy/6fuGFqiuSJKkapc16n5l3AJt1sf34DuuvAruXVYMa01veApdcUvSI7b8//PKXxVOUkiQtS5wxX5V43/vgO9+BK6+E73+/6mokSao/Q5gqM2lScUvyS1+CG2+suhpJkurLEKbKRMC558Lb3w577gmPP151RZIk1Y8hTJVacUW4/HJ46aUiiM2dW3VFkiTVhyFMldtoIzjrLPjjH+ErX6m6GkmS6sMQpoYwYQJ89rPwve8VT0tKktTqDGFqGCefDFtsUUxbcV+5bzWSJKlyhjA1jAED4NJLYbnlihd9z55ddUWSJJXHEKaGMnIkTJ4Md95ZvNrIl1hJklqVIUwNZ4cd4OtfhwsuKAbsS5LUigxhakhf+xrsuCN8/vMwbVrV1UiS1PsMYWpIffrAhRcW75ncbTf4z3+qrkiSpN5lCFPDGjoULrusmEl/331h/vyqK5IkqfcYwtTQ3v1uOPVU+M1v4MQTq65GkqTeYwhTw/vMZ2CffYrB+r/7XdXVSJLUOwxhangR8OMfw4Ybwic/CQ89VHVFkiQtPUOYmsLgwcWLvl97DXbfHebMqboiSZKWjiFMTWO99eC88+DWW+ELX6i6GkmSlo4hTE1l112LAPbDH8JFF1VdjSRJb54hTE3nW9+CbbaBgw+Gu+6quhpJkt4cQ5iaTv/+cPHFsMIK8IlPwEsvVV2RJElLzhCmprTGGkUQu/9+OPBAX/QtSWo+hjA1rW23LW5NXnppMaGrJEnNxBCmpnb00fCxj8EXvwh/+lPV1UiS1HOGMDW1iGLaitGjYY894Mknq65IkqSeMYSp6a20UjGR63PPwd57w+uvV12RJElvzBCmlrDxxvCjH8HUqTB0KIwfvy2jR8PkyVVXJklS1/pVXYDUW/r1K5YXXwQIZs2CiROLfRMmVFmZJEmLKq0nLCLWjoipEXF3RNwVEUd0ccx2EfFCREyvLceXVY9a33HHLXorcvbsYrskSY2mzJ6w14EvZObtEbECcFtE/D4z7+503B8zc+cS69Ay4qGHlmy7JElVKq0nLDMfz8zba+svAfcAa5V1PWnkyK639+sH//pXfWuRJOmN1GVgfkSMBjYDbuli93siYkZE/CYiNqxHPWpNJ54IgwYtvG3AAFhuOdh8c/jFL6qpS5KkrkSW/L6XiBgC3AicmJm/7LRvRWB+ZrZFxIeBUzNz3S7OMRGYCDB8+PAxU6ZMKbVmgLa2NoYMGVL6darSqu37wx9W5+yz38ZTTw1g9dXncNBBD7Dxxi/wjW9swJ13rsROOz3G5z53PwMHzq+61KXWqr/Ddrav+bV6G21f86tHG8eNG3dbZo7tcmdmlrYA/YHfAkf18PiZwLDFHTNmzJish6lTp9blOlVZ1to3d27mV76SGZG50UaZd91VTV29aVn7HbaaVm9fZuu30fY1v3q0EZiW3WSaMp+ODOAc4J7MPLmbY95SO46I2ILi9uh/yqpJy65+/YrblddeW8yq/+53FzPtS5JUlTLHhG0N7AuM7zAFxYcj4pCIOKR2zG7AnRExAzgN2KuWGqVSfOhDMGMGbLklHHAA7LcftLVVXZUkaVlU2hQVmXkzEG9wzBnAGWXVIHVljTXg978vesZOOAFuvRUuuaSYdV+SpHrxtUVaJvXtC8cfD9ddV8ywv8UW8JOfgP2wkqR6MYRpmbbddjB9evH1kENgr73aX3skSVK5DGFa5q2+Ovz613DSSXD55cWcYrfdVnVVkqRWZwiTgD594Nhj4aab4LXX4D3vgdNO8/akJKk8hjCpg/e+F/7+d9hxRzjiCNh1V3j22aqrkiS1IkOY1MnQoXDVVXDKKfCrX8Fmm8Ff/1p1VZKkVmMIk7oQAUceCX/6U/Ek5TbbwHe/C/Ob/21HkqQGYQiTFuPd7y5uT37sY3DMMbDzzvD001VXJUlqBYYw6Q2stFIxmeuZZ8L118OmmxYD+CVJWhqGMKkHIuDQQ4uxYYMHw7hx8M1vwrx5VVcmSWpWhjBpCWy6aTGH2N57w9e+BjvsAE88UXVVkqRmZAiTltAKK8AFF8A558Cf/1wEsz/8oeqqJEnNxhAmvQkR8OlPw9/+Vkxp8aEPFT1jr79edWWSpGZhCJOWwoYbFkHsgAOKMWLbbw+PPlp1VZKkZmAIk5bSoEHFrckLLijGi22ySfEuSkmSFscQJvWSffYpQtiIEbDTTsW8YnPnVl2VJKlRGcKkXrT++sU0FoceWsyw//73w6xZVVclSWpEhjCplw0cWEzsesklcPfdxdOTV15ZdVWSpEZjCJNKsvvuxSuP1lkHPv5xOOIImDOn6qokSY3CECaV6G1vg5tvLl4Gftpp8N73wv33V12VJKkRGMKkkg0YAKecAlddBQ8+CJtvXtyqlCQt2wxhUp3ssgtMnw4bbQR77gmHHAKvvFJ1VZKkqhjCpDoaORJuvBGOPRZ+8hPYcku4996qq5IkVcEQJtVZ//5w0knwm9/A44/D2LHFRK+SpGWLIUyqyI47wowZRQjbb7/i1Ucvv1x1VZKkejGESRVac034wx/g+OPh/PPh3e+Gf/yj6qokSfVgCJMq1q8fnHBCEcaeew622ALOPhsyq65MklQmQ5jUIMaPL56e3GYbOPhgmDABXnyx6qokSWUxhEkNZPhwuPZaOPFEuPhiGDOmmHVfktR6SgthEbF2REyNiLsj4q6IOKKLYyIiTouI+yPijojYvKx6pGbRpw985Stwww3FPGJbbQU//KG3JyWp1ZTZE/Y68IXM3ADYCjgsIjbodMx/AevWlonAj0qsR2oq22xT3J784Afhc5+D3XaD55+vuipJUm8pLYRl5uOZeXtt/SXgHmCtTod9FPh5Fv4KrBwRa5RVk9Rshg2Dq6+G732v+LrZZsUg/tGjYfz4bRk9GiZPrrpKSdKbEVmHexwRMRq4CdgoM1/ssP0a4KTMvLn2+Trg2Myc1un7J1L0lDF8+PAxU6ZMKb3mtrY2hgwZUvp1qmL7ms/dd6/Al7/8Ll58sT8Q/3/7gAHzOProf/KBDzxVXXElaMXfYUet3j5o/TbavuZXjzaOGzfutswc2+XOzCx1AYYAtwG7drHvGuB9HT5fB4xd3PnGjBmT9TB16tS6XKcqtq85jRiRWYwOW3gZNarqynpfq/4O27V6+zJbv422r/nVo43AtOwm05T6dGRE9AcuByZn5i+7OORRYO0On0fUtknqwqPd/N8xaxb885/1rUWStHTKfDoygHOAezLz5G4OuxrYr/aU5FbAC5n5eFk1Sc1u5Mju973jHbDDDnDNNTB/fv1qkiS9OWX2hG0N7AuMj4jpteXDEXFIRBxSO+bXwAPA/cBPgc+WWI/U9E48EQYNWnjboEHFFBbf+AbceSd85COw3npwyik+TSlJjaxfWSfOYrB9vMExCRxWVg1Sq5kwofh63HHw0EPJyJHBiScu2H7ssfDLX8Lpp8NRR8FXv1q8HPzww2GDzhPESJIq5Yz5UpOZMAFmzoTrr7+RmTMXBDCA/v1hzz3h5pvh9tuL9Z/9DDbcELbfHq68EubNq6hwSdJCDGFSi9psMzj3XHjkEfjWt+Bf/4KPfxze/nb47nfh2WerrlCSlm2GMKnFDRsGX/oSPPAAXHZZMdHrMcfAiBHFi8LvuKPqCiVp2WQIk5YR/frBJz5RvJNyxgzYZ59itv1NNoFtty0C2uuvV12lJC07DGHSMmjjjeGss4pbld/9Ljz0EOy+O7ztbcWty2eeqbpCSWp9hjBpGbbqqnD00XD//cWg/fXWg698pbhVecABxeB+SVI5DGGS6NsXPvpR+MMf4K674NOfhksvhTFjYOut4eKLYe7cqquUpNZiCJO0kA02gDPPLG5VnnIKPPkk7LVXMaD/G98oPkuSlp4hTFKXVl4ZjjwS7ruveBXSu94Fxx9fvDpp333h1lurrlCSmpshTNJi9ekDO+0E114L994Ln/kMXHUVbLllsVx4IcyZU3WVktR8DGGSemz99eG004pblaefDi+8UPSKjRoFX/86PPZY1RVKUvMwhElaYiuuCJ/7HNx9d9FDNnZsMV5s1CjYe2/4858hs+oqJamxGcIkvWl9+sAOOxRjxu67r3hR+G9+UzxROXYsnHcevPpq1VVKUmMyhEnqFeusAyefXNyq/NGPivB1wAGw9tpw3HHFdknSAoYwSb1qyBA45BC4885i3rGtt4aTTiqmuNh9d7jpJm9VShIYwiSVJAK2376Yif/f/4ajjoLrriveU7nZZnDOOfDKK1VXKUnVMYRJKt3o0fCd7xS3JM86C+bPh4MOKl6PdOyxMGtW1RVKUv0ZwiTVzaBBcPDBMGMG3HADjBsH3/9+8eLwj38crr8eJk8uQtv48dsyenTxWZJaUb+qC5C07Ikobktuuy08/HAxkP+ss4pblxHtY8aCWbNg4sTieyZMqLBgSSqBPWGSKrX22vC//1uEsaFDFx20P3s2TJoEL75YTX2SVBZ7wiQ1hOWXh2ef7Xrf00/DKqsUA/rf//6iB22bbWDVVetboyT1JnvCJDWMkSO73r766vDVr8IKK8CZZ8LHPlb0mm28cTFB7KWXwpNP1rVUSVpq9oRJahgnnliMAZs9e8G2QYOKSWDbx4TNmQO33lrMN3bjjfCzn8EZZxT73vGOBT1l224La61V/zZIUk8ZwiQ1jPagddxx8NBDyciRwYknLjwof8CA4lbkNtsUx82dC7ffXgSym26CKVOKQf5QPHW57bYLgtno0cXAf0lqBIYwSQ1lwoRiueGGG9luu+3e8Pj+/WHLLYvlmGNg3rxiCoz2nrKrrip6y6B4CKBjT9m66xrKJFXHECappfTtC5tvXixHHllMDHv33Qt6yv7whwVzj73lLQtC2fvfDxtsULyUXJLqwRAmqaX16QMbbVQshx1WTIFx330LespuvBEuuaQ4dujQ4jZne0/ZxhsXoU6SymAIk7RMiYD11y+Wgw8uQtnMmQt6ym68sZg0FmClleB971vQU7b55sXtT0nqDaWFsIg4F9gZeCozN+pi/3bAVcCDtU2/zMz/KaseSepKBLz1rcWy//7FtkceWbin7Fe/KrYPHgzvfe+CnrJ3v7t4UECS3owye8LOA84Afr6YY/6YmTuXWIMkLbERI+CTnywWKOYgaw9lN91UzFkGMHAgbLXVgp6yrbYqptSQpJ4obQhqZt4EdDP/tSQ1j+HDYffdi/nI7rgDnnkGrrgCDj20eJ3SN74B228PK69c3L78ylfgt7+Fl15a9Fy+oFxSu8jOL2rrzZNHjAauWcztyMuBR4DHgKMz865uzjMRmAgwfPjwMVOmTCmp4gXa2toYMmRI6depiu1rfq3exmZqX1tbX+68cyVmzFiZO+5YiX/+cwXmzetDnz7Jeuu9xCabPM/GG7/As8/254wz1mXOnAWj/QcMmMfRR/+TD3zgqQpbUI5m+h2+Gbav+dWjjePGjbstM8d2ta/KELYiMD8z2yLiw8CpmbnuG51z7NixOW3atN4vtpMbbrihR3MUNSvb1/xavY3N3L62NvjLXxbcwrzlFnjtte6PHzWqeDig1TTz77AnbF/zq0cbI6LbEFbZ05GZ+WKH9V9HxJkRMSwzn6mqJknqDUOGwAc/WCwAr75aBLHu/qyfNasYU7bOOosuK65Yt7Il1VllISwi3gI8mZkZEVtQjE/7T1X1SFJZBg4sBu+PGlUErs4GDy6+XnstPP74wvtWW63rcLbOOrDqquXXLqk8ZU5R8QtgO2BYRDwCfB3oD5CZPwZ2Aw6NiNeBV4C9ssx7o5JUse5eUP6Tnyx4P2ZbGzzwANx//8LLDTfABRcsfL6VV+4+oK2+uq9kkhpdaSEsM/d+g/1nUExhIUnLhJ68oHzIkGKm/o03XvT7X3kFHnxwQTD797+Lr7feWsz6P3/+wufpLqCtsYavZ5IagTPmS1IdLekLyjtafvni/ZYbbLDovtdeK251du5Bu+OO4iXmc+cuOHbgQHj727sOaGuv7auapHoxhElSC1huOVh33WLp7PXX4eGHF+1Bu//+Yj6zV19dcGz//vC2t3Ud0EaN6tlrmyZPbu/t25aRI1mkt09SwRAmSS2uX78Fr2Zqf2Kz3fz58Nhji/agtY9De/nlBcf27VsEsa4C2lvfWvSwTZ7ccdxbMGtW8RkMYlJnhjBJWob16VO8pmnEiEWn0MgsXtnUVQ/a5MnwwgsLjo0obmU++STMmbPweWbPhmOPhV13LW6pSioYwiRJXYqAt7ylWN73voX3ZcKzzy7ae3bhhV2f69FHiydBBw0qpt0YNqz4+kbrK6/sQwRqXYYwSdISi4ChQ4tlyy0XbP/jH7ueC23VVeHoo4v3bj799IKv99xTrHe87dlR377FNRYX2DpvW265ctos9TZDmCSp13Q3F9pppy1+TNgrrywcztq/dl6/887i67PPFr1xXVlxxcWHtM7rK6ywZHOq+eCBeoshTJLUa3oyF1pXll8eRo4slp6YN68IYm8U3B55BKZPL9Y7j1Vrt9xyPQ9sN94IX/yiDx6odxjCJEm9amnmQuupvn0XBKSeyCxueXbVu9Y5xE2bVqw//3zPzj17Nhx0EFxxRTFJ7uDBxdfOS1fb27ctt1zjvOHAnr76MYRJklpexILg89a39ux75s4twljHkLbnnl0f++qrcO+9xWun2pfuet660q9fzwNbT8Pd4MHFeZeEU4zUlyFMkqQu9O9fvOJpjTUWbDvmmK4fPBg1qhiv1tHrrxe9bx2DWVtb19u62/7444tunzev520YOHDJwt1JJy08ng+Kz0cfDZtuCgMGLFiWW27BerM9wdoovX2GMEmSeqi7Bw9OPHHRY/v1g5VWKpbekln0sHUX2noa8J5+euHt3T2d2u6JJ2Cjjbrf36/fosGsq7BWxrbujunuFm8j9fYZwiRJ6qE3++BBb4koercGDiweFugt8+cXoeSd7yweZuhstdXgjDOKANhxee21JdvWfpu2q+Nee61YelPHgNa+/vDDRS9lR7NnF79TQ5gkSQ2sHg8e1FufPgtuR3bV03fKKbDHHuXXkblwOFvSkLe4be2fu5tQ+KGHym9fZ4YwSZIENEZPX3vPVVm6m1C4p9Oj9KYmG0onSZLKNGECzJwJ119/IzNntt5TkSeeWPTuddTduL6yGcIkSdIyY8IEOOus4onWiGTUqOJzFWHTECZJkpYpjdLbZwiTJEmqgCFMkiSpAoYwSZKkChjCJEmSKmAIkyRJqoAhTJIkqQKGMEmSpAoYwiRJkipgCJMkSaqAIUySJKkCkZlV17BEIuJpoIv3n/e6YcAzdbhOVWxf82v1Ntq+5tfqbbR9za8ebRyVmat1taPpQli9RMS0zBxbdR1lsX3Nr9XbaPuaX6u30fY1v6rb6O1ISZKkChjCJEmSKmAI695ZVRdQMtvX/Fq9jbav+bV6G21f86u0jY4JkyRJqoA9YZIkSRUwhHUSEedGxFMRcWfVtfS2iFg7IqZGxN0RcVdEHFF1Tb0tIgZGxK0RMaPWxhOqrqkMEdE3Iv4eEddUXUsZImJmRPwjIqZHxLSq6+ltEbFyRFwWEfdGxD0R8Z6qa+otEbF+7ffWvrwYEUdWXVdvi4hJtT9j7oyIX0TEwKpr6k0RcUStbXe1yu+vq7/fI2LViPh9RPyr9nWVetZkCFvUecCOVRdRkteBL2TmBsBWwGERsUHFNfW2OcD4zNwE2BTYMSK2qrakUhwB3FN1ESUbl5mbtugj8qcC12bmO4BNaKHfZWb+s/Z72xQYA8wGrqi2qt4VEWsBnwfGZuZGQF9gr2qr6j0RsRFwMLAFxX+fO0fEOtVW1SvOY9G/378EXJeZ6wLX1T7XjSGsk8y8CXi26jrKkJmPZ+bttfWXKP7gX6vaqnpXFtpqH/vXlpYa+BgRI4CdgLOrrkVLLiJWAt4PnAOQma9l5vOVFlWe7YF/Z2Y9Jtiut37A8hHRDxgEPFZxPb3pncAtmTk7M18HbgR2rbimpdbN3+8fBc6vrZ8PfKyeNRnCllERMRrYDLil4lJ6Xe1W3XTgKeD3mdlqbfwBcAwwv+I6ypTA7yLitoiYWHUxveytwNPAz2q3lM+OiMFVF1WSvYBfVF1Eb8vMR4HvAQ8BjwMvZObvqq2qV90JbBMRQyNiEPBhYO2KayrL8Mx8vLb+BDC8nhc3hC2DImIIcDlwZGa+WHU9vS0z59VuhYwAtqh1rbeEiNgZeCozb6u6lpK9LzM3B/6L4rb5+6suqBf1AzYHfpSZmwEvU+dbIPUQEcsBuwCXVl1Lb6uNG/ooRaBeExgcEftUW1Xvycx7gG8DvwOuBaYD86qsqR6ymC6irndODGHLmIjoTxHAJmfmL6uup0y1WzxTaa0xflsDu0TETGAKMD4iLqy2pN5X62kgM5+iGE+0RbUV9apHgEc69NBeRhHKWs1/Abdn5pNVF1KCDwAPZubTmTkX+CXw3opr6lWZeU5mjsnM9wPPAfdVXVNJnoyINQBqX5+q58UNYcuQiAiKcSj3ZObJVddThohYLSJWrq0vD3wQuLfSonpRZn45M0dk5miKWz3XZ2bL/AscICIGR8QK7evAhyhuj7SEzHwCeDgi1q9t2h64u8KSyrI3LXgrsuYhYKuIGFT7c3V7WujhCoCIWL32dSTFeLCLqq2oNFcDn6qtfwq4qp4X71fPizWDiPgFsB0wLCIeAb6emedUW1Wv2RrYF/hHbcwUwFcy89fVldTr1gDOj4i+FP/IuCQzW3IahxY2HLii+LuNfsBFmXlttSX1usOBybVbdg8AB1RcT6+qhecPAp+pupYyZOYtEXEZcDvFU+d/p/Vml788IoYCc4HDWuHhka7+fgdOAi6JiAOBWcAeda3JGfMlSZLqz9uRkiRJFTCESZIkVcAQJkmSVAFDmCRJUgUMYZIkSRUwhElqehExLyKmd1h6bQb6iBgdES0zT5mkxuE8YZJawSu1V1VJUtOwJ0xSy4qImRHxnYj4R0TcGhHr1LaPjojrI+KOiLiuNis4ETE8Iq6IiBm1pf1VNH0j4qcRcVdE/K72NgYi4vMRcXftPFMqaqakJmUIk9QKlu90O3LPDvteyMx3AWcAP6htOx04PzM3BiYDp9W2nwbcmJmbULzP8a7a9nWBH2bmhsDzwCdq278EbFY7zyHlNE1Sq3LGfElNLyLaMnNIF9tnAuMz84Hay+ufyMyhEfEMsEZmzq1tfzwzh0XE08CIzJzT4Ryjgd9n5rq1z8cC/TPzmxFxLdAGXAlcmZltJTdVUguxJ0xSq8tu1pfEnA7r81gwnnYn4IcUvWZ/iwjH2UrqMUOYpFa3Z4evf6mt/xnYq7Y+Afhjbf064FCAiOgbESt1d9KI6AOsnZlTgWOBlYBFeuMkqTv+q01SK1g+IqZ3+HxtZrZPU7FKRNxB0Zu1d23b4cDPIuKLwNPAAbXtRwBnRcSBFD1ehwKPd3PNvsCFtaAWwGmZ+XwvtUfSMsAxYZJaVm1M2NjMfKbqWiSpM29HSpIkVcCeMEmSpArYEyZJklQBQ5gkSVIFDGGSJEkVMIRJkiRVwBAmSZJUAUOYJElSBf4fSk47Yzds9IUAAAAASUVORK5CYII=",
            "text/plain": [
              "<Figure size 720x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "x = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
        "y = epoch_losses\n",
        "\n",
        "plt.figure(figsize=(10, 6))  # Making the plot bigger\n",
        "plt.plot(x, y, marker='o', linestyle='-', color='b') \n",
        "plt.title(\" Loss Over Epochs\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.grid(True)  \n",
        "plt.xticks(ticks=x)  # Set x-ticks to be exactly where we have data points\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "aHtQDXcXLNpR"
      },
      "outputs": [],
      "source": [
        "def predict_answer(model, tokenizer, dataset, device, question_max_length=max_len_que+1, context_max_length=max_len_context+1):\n",
        "    model.eval()  # Put the model in evaluation mode\n",
        "    predictions = []\n",
        "\n",
        "    with torch.no_grad():  # No need to track gradients for predictions\n",
        "        for item in dataset:\n",
        "            # Separate tokenization for question and context\n",
        "            question_encodings = tokenizer.encode_plus(\n",
        "                item['question'],\n",
        "                None,\n",
        "                add_special_tokens=True,\n",
        "                max_length=question_max_length,\n",
        "                padding='max_length',\n",
        "                return_attention_mask=True,\n",
        "                truncation=True,\n",
        "                return_tensors=\"pt\"\n",
        "            )\n",
        "\n",
        "            context_encodings = tokenizer.encode_plus(\n",
        "                item['context'],\n",
        "                None,\n",
        "                add_special_tokens=True,\n",
        "                max_length=context_max_length,\n",
        "                padding='max_length',\n",
        "                return_attention_mask=True,\n",
        "                truncation=True,\n",
        "                return_tensors=\"pt\"\n",
        "            )\n",
        "\n",
        "            # Combine inputs for the model\n",
        "            inputs = {\n",
        "                'question_ids': question_encodings['input_ids'].to(device),\n",
        "                'question_mask': question_encodings['attention_mask'].to(device),\n",
        "                'context_ids': context_encodings['input_ids'].to(device),\n",
        "                'context_mask': context_encodings['attention_mask'].to(device)\n",
        "            }\n",
        "\n",
        "            # Get model predictions\n",
        "            start_logits, end_logits = model(inputs['question_ids'], inputs['question_mask'], inputs['context_ids'], inputs['context_mask'])\n",
        "\n",
        "            # Convert logits to start and end positions (assuming context_ids for the answer span)\n",
        "            start_position = torch.argmax(start_logits, dim=-1).item()  # Convert to Python int\n",
        "            end_position = torch.argmax(end_logits, dim=-1).item()\n",
        "\n",
        "            # Decode the predicted answer span from the context\n",
        "            answer_ids = inputs['context_ids'].squeeze().tolist()[start_position:end_position + 1]  # Adjust indexing for PyTorch tensor\n",
        "            answer = tokenizer.decode(answer_ids, skip_special_tokens=True)\n",
        "            print(start_position, end_position, answer, answer_ids)\n",
        "            print(item['answers'])\n",
        "            predictions.append(answer)\n",
        "\n",
        "    return predictions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7rL6lMrHCtlc"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UCOkIS6V6PpP"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S0u5S7ORDK_H",
        "outputId": "19740a12-792b-4056-8668-e1b0882d0f72"
      },
      "outputs": [],
      "source": [
        "from collections import Counter\n",
        "\n",
        "def compute_f1(predicted, truth):\n",
        "    predicted_tokens = predicted.split()\n",
        "    truth_tokens = truth.split()\n",
        "    common_tokens = Counter(predicted_tokens) & Counter(truth_tokens)\n",
        "    num_same = sum(common_tokens.values())\n",
        "\n",
        "    if num_same == 0:\n",
        "        return 0\n",
        "\n",
        "    precision = 1.0 * num_same / len(predicted_tokens)\n",
        "    recall = 1.0 * num_same / len(truth_tokens)\n",
        "    f1 = (2 * precision * recall) / (precision + recall)\n",
        "    return f1\n",
        "\n",
        "def compute_exact_match(predicted, truth):\n",
        "    return int(predicted.strip() == truth.strip())\n",
        "\n",
        "# Assume `predictions` is a list of predicted answers, and `dataset` has the ground truth\n",
        "exact_matches = []\n",
        "f1_scores = []\n",
        "\n",
        "for prediction, item in zip(predictions, tokenized_datasets['train']):\n",
        "    # print(item)\n",
        "    ground_truths = item['answers']['text']  # Assuming this is how your dataset stores ground truth answers\n",
        "    best_match = max(ground_truths, key=lambda gt: compute_f1(prediction, gt))\n",
        "\n",
        "    exact_match = compute_exact_match(prediction, best_match)\n",
        "    f1_score = compute_f1(prediction, best_match)\n",
        "\n",
        "    exact_matches.append(exact_match)\n",
        "    f1_scores.append(f1_score)\n",
        "\n",
        "# Calculate and print the average scores\n",
        "avg_exact_match = sum(exact_matches) / len(exact_matches)\n",
        "avg_f1_score = sum(f1_scores) / len(f1_scores)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average Exact Match on training:  0.532\n",
            "Average F1 Score on training:  0.653\n"
          ]
        }
      ],
      "source": [
        "\n",
        "print(f\"Average Exact Match on training: \", avg_exact_match)\n",
        "print(f\"Average F1 Score on training: \", avg_f1_score)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "exact_matches = []\n",
        "f1_scores = []\n",
        "\n",
        "for prediction, item in zip(predictions, tokenized_datasets['validation']):\n",
        "    # print(item)\n",
        "    ground_truths = item['answers']['text']  # Assuming this is how your dataset stores ground truth answers\n",
        "    best_match = max(ground_truths, key=lambda gt: compute_f1(prediction, gt))\n",
        "\n",
        "    exact_match = compute_exact_match(prediction, best_match)\n",
        "    f1_score = compute_f1(prediction, best_match)\n",
        "\n",
        "    exact_matches.append(exact_match)\n",
        "    f1_scores.append(f1_score)\n",
        "\n",
        "# Calculate and print the average scores\n",
        "avg_exact_match = sum(exact_matches) / len(exact_matches)\n",
        "avg_f1_score = sum(f1_scores) / len(f1_scores)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "0LjwB7eFDofI"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average Exact Match on validation:  0.4432\n",
            "Average F1 Score on validation:  0.5125\n"
          ]
        }
      ],
      "source": [
        "print(f\"Average Exact Match on validation: \", avg_exact_match)\n",
        "print(f\"Average F1 Score on validation: \", avg_f1_score)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "220aa364605b49968cfca3d129fb3167": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2a3a05ccc4234db69ad4b6c907feebd4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6d25d66f87ac4777a384847f8192fd7d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f08a5120603741fba45928b84c300c55",
            "placeholder": "​",
            "style": "IPY_MODEL_220aa364605b49968cfca3d129fb3167",
            "value": "Map: 100%"
          }
        },
        "aa5613cc8b724c4880e9a6883da1d07c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ba620aea7e064569a4c31941e0355304": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d056cf3774264d85ab2646aea196f1db": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d0b986912f5d4311b27febff756dc84d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d67a401bb38f409c85d072233232aabf",
            "max": 50000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ba620aea7e064569a4c31941e0355304",
            "value": 50000
          }
        },
        "d67a401bb38f409c85d072233232aabf": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f08a5120603741fba45928b84c300c55": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f1f8eebe4a2f49d5ab836a9483b87d35": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6d25d66f87ac4777a384847f8192fd7d",
              "IPY_MODEL_d0b986912f5d4311b27febff756dc84d",
              "IPY_MODEL_fc081644980e47f19a5a89ccc9487a21"
            ],
            "layout": "IPY_MODEL_d056cf3774264d85ab2646aea196f1db"
          }
        },
        "fc081644980e47f19a5a89ccc9487a21": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2a3a05ccc4234db69ad4b6c907feebd4",
            "placeholder": "​",
            "style": "IPY_MODEL_aa5613cc8b724c4880e9a6883da1d07c",
            "value": " 50000/50000 [01:15&lt;00:00, 641.45 examples/s]"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
